### 锁

**互斥锁、自旋锁、读写锁、乐观锁、悲观锁**

最底层是两种就是互斥锁和自旋锁，很多高级的锁都是基于它们实现的

* 互斥锁：加锁失败后，线程会**释放 CPU** ，给其他线程；

  * 互斥锁是一种「独占锁」，比如当线程 A 加锁成功后，此时互斥锁已经被线程 A 独占了，只要线程 A 没有释放手中的锁，线程 B 加锁就会失败，于是就会释放 CPU 让给其他线程再去尝试获取锁，**既然线程 B 释放掉了 CPU，自然线程 B 加锁的代码就会被阻塞**。

  * 对于互斥锁加锁失败而阻塞的现象，是由**操作系统内核**实现的。当加锁失败时，内核会将线程置为「睡眠」状态，等到锁被释放后，内核会在合适的时机唤醒线程，当这个线程成功获取到锁后，于是就可以继续执行。
  * 互斥锁加锁失败时，会从用户态陷入到内核态，让内核帮我们切换线程，会有**两次线程上下文切换的成本**![image-20210318112558399](https://gitee.com/picgo-table/picgo-img/raw/master/image/image-20210318112558399.png)
  * 线程上下文切换：CPU切换前把当前**任务的状态**保存下来，以便下次切换回这个任务时可以再次加载这个任务的状态，然后加载下一任务的状态并执行。任务的状态保存及再加载, 这段过程就叫做**上下文切换。**

* 自旋锁：
  * 通过 CPU 提供的 `CAS` 函数（*Compare And Swap*），在「**用户态**」完成加锁和解锁操作，**不会主动产生线程上下文切换**

  * 加锁时：查看锁的状态，如果锁是空闲的，则将锁设置为当前线程持有；

  * CAS 函数就把这两个步骤合并成一条**硬件级指令**，形成**原子指令**，这样就保证了这两个步骤是不可分割的，要么一次性执行完两个步骤，要么两个步骤都不执行。

    使用自旋锁的时候，当发生多线程竞争锁的情况，加锁失败的线程会「忙等待」，直到它拿到锁。这里的「忙等待」可以用 `while` 循环等待实现，不过最好是使用 CPU 提供的 `PAUSE` 指令来实现「忙等待」，因为可以减少循环等待时的耗电量。

    自旋锁是最比较简单的一种锁，一直自旋，利用 CPU 周期，直到锁可用。**需要注意，在单核 CPU 上，需要抢占式的调度器（即不断通过时钟中断一个线程，运行其他线程）。否则，自旋锁在单 CPU 上无法使用，因为一个自旋的线程永远不会放弃 CPU。**

    自旋锁开销少，在多核系统下一般不会主动产生线程切换，适合异步、协程等在用户态切换请求的编程方式，但如果被锁住的代码执行时间过长，自旋的线程会长时间占用 CPU 资源，所以自旋的时间和被锁住的代码执行的时间是成「正比」的关系

    自旋锁与互斥锁使用层面比较相似，但实现层面上完全不同：**当加锁失败时，互斥锁用「线程切换」来应对，自旋锁则用「忙等待」来应对**。它俩是锁的最基本处理方式，更高级的锁都会选择其中一个来实现，比如读写锁既可以选择互斥锁实现，也可以基于自旋锁实现

* 读写锁

  * 读写锁的工作原理是：
    - 当「写锁」没有被线程持有时，多个线程能够**并发地持有读锁**，这大大提高了共享资源的访问效率，因为「读锁」是用于读取共享资源的场景，所以多个线程同时持有读锁也不会破坏共享资源的数据。
    - 但是，一旦「写锁」被线程持有后，读线程的获取**读锁的操作会被阻塞**，而且其他写线程的获取写锁的操作也会被阻塞。、
  * 读写锁可以分为「读优先锁」和「写优先锁」。
    * **读优先锁**：当读线程 A 先持有了读锁，写线程 B 在获取写锁的时候，会被阻塞，并且在阻塞过程中，后续来的读线程 C 仍然可以成功获取读锁，最后直到读线程 A 和 C 释放读锁后，写线程 B 才可以成功获取读锁。
    * **写优先锁**：当读线程 A 先持有了读锁，写线程 B 在获取写锁的时候，会被阻塞，并且在阻塞过程中，后续来的读线程 C 获取读锁时会失败，于是读线程 C 将被阻塞在获取读锁的操作，这样只要读线程 A 释放读锁后，写线程 B 就可以成功获取读锁。

  * **公平读写锁：用队列把获取锁的线程排队，不管是写线程还是读线程都按照先进先出的原则加锁即可，这样读线程仍然可以并发，也不会出现「饥饿」的现象。**

* 悲观锁：

  * 认为**多线程同时修改共享资源的概率比较高，于是很容易出现冲突，所以访问共享资源前，先要上锁**。
  * 共享锁和排它锁是悲观锁的不同的实现
  * 共享锁
    * 共享锁指的就是对于多个不同的事务，对同一个资源共享同一个锁。有点类似读写锁
    * 对于selecct语句，通过在执行语句后面加上`lock in share mode`就代表对某些资源加上共享锁了。
  * 排他锁：
    * 对于update,insert,delete语句会自动加排它锁
    * 与共享锁类型，在需要执行的语句后面加上**for update**就可以了（对于Innodb引擎语句后面加上for update表示把此**行数据**锁定，MyISAM则是**锁定整个表**。）

* 乐观锁：**乐观锁全程并没有加锁，所以它也叫无锁编程**。**只有在冲突概率非常低，且加锁成本非常高的场景时，才考虑使用乐观锁。**

  * 先修改完共享资源，再验证这段时间内有没有发生冲突，如果没有其他线程在修改资源，那么操作完成，如果发现有其他线程已经修改过这个资源，就放弃本次操作。
  * 乐观锁不是数据库自带的，需要我们自己去实现：
    * 在表中的数据进行操作时(更新)，先给数据表加一个**版本(version)**字段，每操作一次，将那条记录的版本号加1。也就是先查询出那条记录，获取出version字段,如果要对那条记录进行操作(更新),则先判断此刻version的值是否与刚刚查询出来时的version的值相等，如果相等，则说明这段期间，没有其他程序对其进行操作，则可以执行更新，将version字段的值加1；如果更新时发现此刻的version值与刚刚获取出来的version的值不相等，则说明这段期间已经有其他程序对其进行操作了，则不进行更新操作。
  * 应用：多人同时在线编辑文档
  
* jdk1.6锁升级

  * 1. 无锁态

    对象刚创建，没有任何锁

    2. 偏向锁

    当处于无锁态时，如果**同步代码**被线程访问，线程自动获得锁，状态变为偏向锁。
     这个时候，锁对象的**markword**保存了：**指向该线程的指针。**

    此时，如果发生**线程竞争锁，则锁升级为轻量锁**。

    3. 轻量锁（自旋锁）

    当多个线程竞争一个偏向锁，则锁升级为轻量锁。
     轻量级锁对象的**markword**保存了：**指向某个线程栈LockRecord的指针。**

    当线程竞争锁时，使用CAS（compare and swap）操作尝试将锁markword中的**指针Klass Pointer指向自己（的LockRecord）**，如果成功，那么就获得锁。如果失败，那么重新竞争（**自旋**）。

    如果一直自旋下去，会非常消耗cpu资源（可能会发生**内存溢出OOM**），因为**所有竞争的线程都在运行。**
     所以当自旋到一定条件之后（竞争剧烈到一定程度），锁会升级为**重量级锁。**

    4. 重量级锁

    系统提供的锁机制。开销大，进行了从**用户态到内核态的转换。**

    重量级锁的优势在于，**没有获得锁的线程将被挂起，不消耗资源。**

    5. CAS（Compare and Swap）

    CAS 操作包含三个操作数 —— **内存位置**（V）、**预期原值**（A）**和新值**(B)。 如果**内存位置的值与预期原值相匹配**，那么处理器会自动将该位置值更新为新值 。否则，处理器不做任何操作。无论哪种情况，它都会在 **CAS 指令之前返回该 位置的值**。（在 CAS 的一些特殊情况下将仅返回 CAS 是否成功，而不提取当前 值。）CAS 有效地说明了“我认为位置 V 的值应该等于 A；如果等于该值，则将 B 放到这个位置；否则，不要更改该位置，只告诉我这个位置现在的值即可。

    通常将 CAS 用于同步的方式是**从地址 V 读取值 A**，执行多步计算来获得新 值 B，然后使用 CAS 将 V 的值从 A 改为 B。如果 V 处的值尚未同时更改，则 CAS 操作成功。
 这个操作的含义是，如果CAS执行成功，说明在竞争线程保存锁副本到CAS操作执行期间，其他线程没有竞争到锁，那么本线程竞争成功；如果执行失败，即a不等于b，说明在**竞争线程保存锁副本到CAS操作执行期间**，其他线程抢占了这个锁，那么本线程就竞争失败了，于是开始自旋重新竞争锁。
    
    * **ABA问题**。因为CAS需要在操作值的时候检查下值有没有发生变化，如果没有发生变化则更新，但是如果一个值原来是A，变成了B，又变成了A，那么使用CAS进行检查时会发现它的值没有发生变化，但是实际上却变化了。ABA问题的解决思路就是使用**版本号**。在变量前面追加上版本号，每次变量更新的时候把版本号加一，那么A－B－A 就会变成1A-2B－3A。

### 多线程

* 交替打印ABCABCABC

  * 使用Lock->ReentrantLock 和Condition（await 、signal、signalAll）

    ```java
    public class Lock_Condition_ABC {
        private static Lock lock = new ReentrantLock();
        private static Condition A = lock.newCondition();
        private static Condition B = lock.newCondition();
        private static Condition C = lock.newCondition();
        private static int count = 0;
        static class ThreadA extends Thread {
            @Override
            public void run() {
                try {
                    lock.lock();
                    for (int i = 0; i < 10; i++) {
                        while (count % 3 != 0){//注意这里是不等于0，也就是说没轮到该线程执行，之前一直等待状态
                            A.await(); //该线程A将会释放lock锁，构造成节点加入等待队列并进入等待状态
                        }
                        System.out.print("A");
                        count++;
                        B.signal(); // A执行完唤醒B线程
                    }
                } catch (InterruptedException e) {
                    e.printStackTrace();
                } finally {
                    lock.unlock();
                }
            }
        }
        static class ThreadB extends Thread {
            @Override
            public void run() {
                try {
                    lock.lock();
                    for (int i = 0; i < 10; i++) {
                        while (count % 3 != 1)
                            B.await();// B释放lock锁，当前面A线程执行后会通过B.signal()唤醒该线程
                        System.out.print("B");
                        count++;
                        C.signal();// B执行完唤醒C线程
                    }
                } catch (InterruptedException e) {
                    e.printStackTrace();
                } finally {
                    lock.unlock();
                }
            }
        }
        static class ThreadC extends Thread {
            @Override
            public void run() {
                try {
                    lock.lock();
                    for (int i = 0; i < 10; i++) {
                        while (count % 3 != 2)
                            C.await();// C释放lock锁
                        System.out.print("C");
                        count++;
                        A.signal();// C执行完唤醒A线程
                    }
                } catch (InterruptedException e) {
                    e.printStackTrace();
                } finally {
                    lock.unlock();
                }
            }
        }
        public static void main(String[] args) throws InterruptedException {
            new ThreadA().start();
            new ThreadB().start();
            new ThreadC().start();
        }
    }
    ```

### 线程池

* **池化技术的思想主要是为了减少每次获取资源的消耗，提高对资源的利用率。**

* **线程池**提供了限制和管理资源（包括执行一个任务）。每个**线程池**还维护一些基本统计信息，例如已完成任务的数量。

* 作用：**降低资源消耗**、提高响应速度、提高线程的可管理性

* 使用线程池
  * **`Runnable` 接口**不会返回结果或抛出检查异常，**`Callable` 接口**会回调
  * **`execute()`方法用于提交不需要返回值的任务，所以无法判断任务是否被线程池执行成功与否；**
  * **`submit()`方法用于提交需要返回值的任务。线程池会返回一个 `Future` 类型的对象，通过这个 `Future` 对象可以判断任务是否执行成功**，并且可以通过 `Future` 的 `get()`方法来获取返回值，`get()`方法会阻塞当前线程直到任务完成，而使用 `get（long timeout，TimeUnit unit）`方法则会阻塞当前线程一段时间后立即返回，这时候有可能任务没有执行完。

* 创建线程池
  * **FixedThreadPool 和 SingleThreadExecutor** ：
    * 分别返回固定数量和一个线程的线程池，允许请求的**队列**长度为 Integer.MAX_VALUE ，可能堆积大量的请求，从而导致OOM。
  * **CachedThreadPool 和 ScheduledThreadPool** ：允许创建的**线程**数量为 Integer.MAX_VALUE ，可能会创建大量线程，从而导致OOM。
    * CachedThreadPool ：线程数根据请求任务增加

* 一般使用构造方法ThreadPoolExecutor 创建线程池

  * **`ThreadPoolExecutor` 3 个最重要的参数：**

    - **`corePoolSize` :** 核心线程数线程数定义了最小可以同时运行的线程数量。
    - **`maximumPoolSize` :** 当队列中存放的**任务达到队列容量**的时候，当前可以同时运行的线程数量变为最大线程数。
    - **`workQueue`:** 当新任务来的时候会先判断当前运行的线程数量是否达到核心线程数，如果达到的话，线程会先被存放在队列中。

    `ThreadPoolExecutor`其他常见参数:

    1. **`keepAliveTime`**: 当线程池中的线程数量大于 `corePoolSize` 的时候，如果这时没有新的任务提交，核心线程外的线程不会立即销毁，而是会等待，直到等待的时间超过了 `keepAliveTime`才会被回收销毁；
    2. **`unit`** : `keepAliveTime` 参数的时间单位。
    3. **`threadFactory`** :executor 创建新线程的时候会用到。
    4. **`handler`** :饱和策略。创建的线程**超过maximumPoolSize**的任务拒绝策略

* 饱和策略：

  * **`ThreadPoolExecutor.AbortPolicy`**：抛出 `RejectedExecutionException`来拒绝新任务的处理。
  * **`ThreadPoolExecutor.CallerRunsPolicy`**：**调用执行自己的线程运行任务**。但是这种策略会降低对于新任务提交速度，影响程序的整体性能。另外，这个策略喜欢增加队列容量。如果您的应用程序可以承受此延迟并且你不能丢弃任何一个任务请求的话，你可以选择这个策略。
  * **`ThreadPoolExecutor.DiscardPolicy`：** **不处理新任务**，直接丢弃掉。
  * **`ThreadPoolExecutor.DiscardOldestPolicy`：** **丢弃最旧的未处理**的任务请求。

* 线程池原理
  
  * 1）如果当前运行的线程少于corePoolSize，则创建新的线程来执行任务。
    2）如果运行的线程等于或者多余corePoolSize，则将任务加入workQueue中，在等待队列中，等待有新的线程可以运行。
    3）如果workQueue队列满了，且没有超过maximumPoolSize，则创建新的线程来处理任务。
    4）如果创建的线程超过maximumPoolSize，任务会拒绝，并调用RejectExecutionHandler.rejectedExecution()方法。
  
* 应用：

  * 在实际应用中使用java中的线程池，我构建了一个线程数为5个线程池，然后采用分段批量提取的方式每500条为一组数据进行图片信息的提取，然后再把这些通过Threadpool的execute方法交给线程池中的线程进行处理，即充分使用了CPU硬件资源又加快了大数据情况下程序的处理效率。
  * 有反馈接口（也就是我们接收到请求，需要立即响应，并且还要有一个接口推送给他们其他计算结果），推送过程耗时、或者说两个接口不能是同时返回，有先后顺序。

### JUC

* 包括：volatile、Lock、等待唤醒机制、线程池、闭锁（CountDownLatch）、Callable接口、concurrentHashMap、Atomic

* CountDownLatch:  一个同步辅助器，允许一个或多个线程一直等待，直到一组在其他线程执行的操作全部完成。
  * 它的构造方法，会传入一个 count 值，用于计数。
  * 当一个线程调用**await**方法时，就会阻塞当前线程。每当有**其他线程**调用一次 **countDown** 方法时，计数就会减 1。当 **count 的值等于 0** 的时候，被阻塞的线程才会继续运行。
* 应用：
    * 秒杀活动时，让一组线程在指定时刻(秒杀时间)执行抢购，这些线程在准备就绪后，进行等待(CountDownLatch.await())，直到秒杀时刻的到来，然后一拥而上；
    * 很多时候，我们的并发任务，存在前后依赖关系；比如数据详情页需要同时调用多个接口获取数据，并发请求获取到数据后、需要进行结果合并；或者多个数据操作完成后，需要数据check；这其实都是：在多个线程(任务)完成后，进行汇总合并的场景。**让单个线程等待：多个线程(任务)完成后，进行汇总合并**
  
* CyclicBarrier
  * 一组线程会互相等待，某个线程就绪后**计数加1**，**直到所有线程都到达一个同步点**
  * CyclicBarrier 提供了两种构造方法，一个指的是需要**几个线程一起就绪**，才可以使所有线程取消阻塞等待。
  * 第二个额外指定了一个参数 `Runnable barrierAction`，用于在所有线程达到屏障时，优先执行 **barrierAction** 任务 
  * 线程调用 await() 表示自己已经到达栅栏
    * BrokenBarrierException 表示栅栏已经被破坏，破坏的原因可能是其中一个线程 await() 时被中断或者超时
  
* Semaphore：
  * Semaphore **信号量**，用来控制同一时间，**资源可被访问 的线程数量**，需要**拿到许可才能执行**，一般可用于**流量的控制。**
  
  * 构造函数需要传入一个 boolean 值的参数，控制抢锁是否是公平的。**默认是非公平**，可以传入 true 来使用公平锁
  
  * void acquire():从此信号量获取一个许可，在提供一个许可前一直将线程阻塞，否则线程被中断。
  
    　　void release():释放一个许可，将其返回给信号量。
  
    　　int availablePermits():返回此信号量中当前可用的许可数。
  
    　　boolean hasQueuedThreads():查询是否有线程正在等待获取。

1. CountDownLatch 是一个线程等待其他线程， CyclicBarrier 是多个线程互相等待。
2. CountDownLatch 的计数是减 1 直到 0，CyclicBarrier 是**加 1，直到指定值。**
3. CountDownLatch 是一次性的， CyclicBarrier  可以循环利用。
4. CyclicBarrier 可以在最后一个线程达到屏障之前，选择先执行一个操作。
5. Semaphore ，需要拿到许可才能执行，并可以选择公平和非公平模式。

### AQS

* 信号量：
  * 信号量（Semaphore）是操作系统提供的一种**进程间常见的通信方式**，主要用来**协调并发程序对共享资源的访问**，操作系统可以保证对信号量操作的**原子性**。
    - 信号量由一个**共享整型变量 S 和两个原子操作 P、V 组成**，S 只能通过 P 和 V 操作来改变
    - P 操作：即**请求资源**，意味着 **S 要减 1**，如果 S <  0, 则表示没有资源了，此时线程要进入等待队列（同步队列）等待
    - V 操作:  即**释放资源**，意味着 **S 要加 1**， 如果 S <= 0，说明等待队列里有线程，此时S+1后就需要唤醒线程。

* `ReentrantLock`、`ReentrantReadWriteLock`、`CountDownLatch`、`Semaphore`等都是基于`AQS`来实现的。

* 实现原理：

  * ![image-20210318161551948](https://gitee.com/picgo-table/picgo-img/raw/master/image/image-20210318161551948.png)

  * `AQS`中 维护了一个`volatile int state`（**代表共享资源的状态量**）和一个`FIFO`线程等待队列CLH（多线程争用资源被阻塞时会进入此队列）。

    这里`volatile`能够保证多线程下的可见性，当`state=1`则代表当前对象锁已经**被占有**，其他线程来加锁时则会失败，加锁失败的线程会被**放入CLH**中，线程会被`UNSAFE.park()`操作挂起，等待其他获取锁的线程释放锁才能够被唤醒。

    另外`state`的操作都是通过`CAS`来保证其并发修改的线程安全性。

* 锁的实现方法：

  * getState()：获取锁的标志state值
  * setState()：设置锁的标志state值
  * tryAcquire(int)：独占方式获取锁。尝试获取资源，成功则返回true，失败则返回false。、
    * `nonfairTryAcquire()`方法中首先会获取`state`的值，如果不为0则说明当前对象的锁已经被其他线程所占有，接着判断占有锁的线程是否为当前线程，如果是则累加`state`值，这就是可重入锁的具体实现，累加`state`值，释放锁的时候也要依次递减`state`值。
    * 如果`state`为0，则执行`CAS`操作，尝试更新`state`值为1，如果更新成功则代表当前线程获取锁成功。
  * tryRelease(int)：独占方式释放锁。尝试释放资源，成功则返回true，失败则返回false。ReentrantLock默认非公平锁：

  * **ReentrantLock非公平锁**，新的线程一进来直接利用`CAS`尝试抢占锁，体现了非公平锁
  * 如果抢占成功`state`值被改为1，且设置对象独占锁线程为当前线程。
  * 如果state不为0，执行`tryAcquire()`后会返回false，接着执行`addWaiter(Node.EXCLUSIVE)`逻辑，将自己加入到CLH中，等着其他线程释放锁来唤醒它。
  * 释放锁：当之前的A线程释放锁后，会唤醒CLH队列中head节点的后置节点线程B，线程B唤醒后继续通过tryAcquire()方法使用CAS操作尝试改变state值来获取锁，失败则挂起

* 公平锁

  * 公平锁在加锁的时候，会先判断`AQS`等待队列中是存在节点，如果存在节点则会直接入队等待
  * 公平锁在获取锁是也是首先会执行`acquire()`方法，只不过公平锁单独实现了`tryAcquire()`方法

* condition（await / signal） 和 wait/notify

  * Condition 可以精准的对多个不同条件进行控制， wait/signal 只能和 synchronized 关键字一起使用，并且**只能唤醒一个**或者全部的等待队列；
  * Condition 需要使用 Lock 进行控制，使用的时候要注意 lock() 后及时的 unlock()，Condition 有类似于 await 的机制，因此不会产生加锁方式而产生的死锁出现，同时底层实现的是 **park/unpark** 的机制，因此也**不会产生先唤醒再挂起的死锁**，一句话就是不会产生死锁，但是 **wait/notify 会产生先唤醒再挂起的死锁。**

### 限流

* 限流算法有：令牌桶、计数器、滑动窗口、漏桶、semaphore信号量的接口限流

* **semaphore**：

  * Semaphore俗称信用量，是JUC包下一个并发工具类，其实基于AQS实现的共享锁模式，包含非公平锁和公平锁实现，主要用用于控制多线程的并发访问次数，可做高并发下限流。

* **滑动窗口**

  * 滑动窗口算法是将时间周期分为N个小周期，分别记录每个小周期内访问次数，并且根据时间滑动删除过期的小周期。

* **计数器**

  * 计数器算法是使用计数器在周期内累加访问次数，当达到设定的限流值时，触发限流策略。下一个周期开始时，进行清零，重新计数。

    此算法在单机还是分布式环境下实现都非常简单，使用**redis的incr原子自增性和线程安全**即可轻松实现。

* **令牌桶算法**

  * 令牌桶算法是程序以r（r=时间周期/限流值）的固定速率向令牌桶中增加令牌，直到令牌桶满，请求到达时向令牌桶请求令牌，如**获取到令牌则通过请求**，否则触发限流策略
  * ![image-20210327094832352](https://gitee.com/picgo-table/picgo-img/raw/master/image/image-20210327094832352.png)

* **漏桶**

  * 漏桶算法是**访问请求到达时直接放入漏桶**，如当前容量已达到上限（限流值），则进行丢弃（触发限流策略）。**漏桶以固定的速率进行释放访问请求（即请求通过），直到漏桶为空。**
  * ![image-20210327094851543](https://gitee.com/picgo-table/picgo-img/raw/master/image/image-20210327094851543.png)

### synchronized

* JVM中的对象构成	

* ![image-20210319131645471](https://gitee.com/picgo-table/picgo-img/raw/master/image/image-20210319131645471.png)
  * **对象头**

    * **Mark Word（标记字段）**：默认存储对象的HashCode，分代年龄和**锁标志位**信息。它会根据对象的状态复用自己的存储空间，也就是说在运行期间Mark Word里**存储的数据会随着锁标志位的变化而变化。**
    - **Klass Point（类型指针）**：对象指向它的类元数据的指针，虚拟机通过这个指针来**确定这个对象是哪个类的实例**。
    
  * **实例数据**：这部分主要是存放**类的数据信息，父类的信息**。
    
  * **对齐填充**：由于虚拟机要求对象起始地址必须是8字节的整数倍，填充数据不是必须存在的，仅仅是为了字节对齐。一个空对象8个字节
  
* 有序性

  * as-if-serial：不管编译器和CPU如何重排序，必须保证在单线程情况下程序的结果是正确的，还有就是有数据依赖的也是不能重排序的。
  
* 可见性：Java内存模型是对共享数据的可见性、有序性、和原子性的规则和保障。

* 原子性：确保同一时间只有一个线程能拿到锁

* 可重入性：可以避免一些死锁的情况

  * synchronized锁对象的时候有个**计数器**，他会记录下线程获取锁的次数，在执行完对应的代码块之后，计数器就会-1，**直到计数器清零，就释放锁**了。

* 不可中断性：

  * 不可中断就是指，一个线程获取锁之后，另外一个线程处于阻塞或者等待状态，前一个不释放，后一个也一直会阻塞或者等待，不可以被中断。Lock的tryLock方法是可以被中断的。

* **同步代码**

  * 当我们进入一个方法或对象的时候，执行**monitorenter**，就会获取当前对象的一个所有权，这个时候monitor进入数为1，当前的这个线程就是这个monitor的owner。
  * 如果你已经是这个monitor的owner了，你再次进入，就会把进入数+1.
  * 同理，当他执行完**monitorexit**，对应的进入数就-1，直到为0，才可以被其他线程持有。

  所有的互斥，其实在这里，就是看你能否获得monitor的所有权，一旦你成为owner就是获得者。

* **同步方法**：

  * 同步方法的时候，一旦执行到这个方法，就会先判断是否有标志位，然后，**ACC_SYNCHRONIZED**会去隐式调用两个指令：monitorenter和monitorexit

* 重量级锁
  * 我们所有的程序都在用户空间运行，进入用户运行状态也就是（用户态），但是很多操作可能涉及内核运行，比如当进行 I/O，我们就会进入内核运行状态（内核态）。
  * 重量级锁就是通过**内核来操作线程**。因为**频繁出现**内核态与用户态的**切换**，会**严重影响性能**。升级为重量级锁时会在**堆中**创建 **monitor** 对象，并将 **（该锁的）Mark Word 指向该 monitor** (请求的线程) 对象。

* 1.6锁升级过程：无锁=》偏向锁=》轻量级锁=》重量级锁

  * ![image-20210319141245577](https://gitee.com/picgo-table/picgo-img/raw/master/image/image-20210319141245577.png)

  * 偏向锁：

    * 对象头是由 Mark Word 和 Klass pointer 组成，锁争夺也就是**对象头指向的Monitor对象的争夺**，一旦有线程持有了这个对象，标志位修改为1，就进入偏向模式，该对象锁就成为该线程的偏向锁，同时会**把这个线程的ID记录在对象的Mark Word**中。

      这个过程是采用了CAS乐观锁操作的，每次同一线程进入，虚拟机就不进行任何同步的操作了，对标志位+1就好了，不同线程过来，CAS会失败，也就意味着获取锁失败。

      ![image-20210319142007416](https://gitee.com/picgo-table/picgo-img/raw/master/image/image-20210319142007416.png)

  * 轻量级锁

    * 如果这个对象是无锁的，jvm就会在当前线程的**栈帧中建立一个叫锁记录（Lock Record）**的空间，用来存储锁对象的**Mark Word 拷贝**，然后把**Lock Record中的owner**指向当前目标资源对象。

      JVM接下来会利用**CAS**尝试把对象原本指向**Mark Word 的指针转为指向 Lock Record** ，成功就说明加锁成功，改变锁标志位，执行相关同步操作。

      如果失败了，就会判断当前对象的Mark Word是否指向了当前线程的栈帧，是则表示当前的线程已经持有了这个对象的锁，否则说明被其他线程持有了，继续锁升级，修改锁的状态，之后等待的线程也阻塞。

    * ![image-20210319142557898](https://gitee.com/picgo-table/picgo-img/raw/master/image/image-20210319142557898.png)

  * 自旋锁

    * 自旋，过来就不断自旋，防止线程被挂起，一旦可以获取资源，就直接尝试成功，直到超出阈值，自旋锁的**默认大小是10次**，-XX：PreBlockSpin可以修改。失败就升级为重量级锁

* 与ReentrantLock区别
  * synchronized是**关键字**，是JVM层面的底层啥都帮我们做了，而Lock是一个**接口**，是JDK层面的有丰富的API。
  * synchronized会**自动释放锁**，而Lock**必须手动释放锁**。
  * synchronized是**不可中断的**，Lock**可以中断也可以不中断**。
  * 通过Lock可以**知道线程有没有拿到锁**，而synchronized不能。
  * synchronized能**锁住方法和代码块**，而Lock**只能锁住代码块**。
  * Lock可以**使用读锁提高多线程读效率**。
  * synchronized是**非公平锁**，ReentrantLock可以**控制是否是公平锁。**
  
* 代码块

  * **1.普通代码块：**

    类中方法的方法体

    **2.构造代码块**：

    构造块会在创建对象时被调用，每次**创建时都会被调用**，优先于类构造函数执行。

    **3.静态代码块：**

    用static{}包裹起来的代码片段，**只会执行一次**。**静态代码块优先于构造块执行。**

    **4.同步代码块：**

    使用synchronized（）{}包裹起来的代码块，在多线程环境下，对共享数据的读写操作是需要互斥进行的，否则会导致数据的不一致性。同步代码块需要写在方法中。

### volatile

### volatile

* 每个线程操作数据的时候会**把数据从主内存读取到自己的工作内存**，如果他操作了数据并且写回主内存了，他其他已经读取的线程的变量副本就会失效了（MESI缓存一致性协议），需要都数据进行操作又要再次去主内存中读取了。

  volatile保证不同线程对共享变量操作的可见性，也就是说一个线程修改了volatile修饰的变量，当修改写回主内存时，**另外一个线程立即看到最新的值。**

* **MESI**（缓存一致性协议）：当**CPU写数据**时，如果发现操作的变量是**共享变量**，即在其他CPU中也存在该变量的副本，会**发出信号通知其他CPU将该变量的缓存行置为无效状态**，因此当其他CPU需要读取这个变量时，发现自己缓存中缓存该变量的缓存行是无效的（**嗅探**），那么它就会**从内存重新读取。**
* **嗅探**：每个处理器**通过嗅探在总线上传播的数据来检查自己缓存的值是不是过期**了，当处理器发现**自己缓存行对应的内存地址被修改**，就会将当前处理器的缓存行设置成无效状态，当处理器对这个数据进行修改操作的时候，会重新从系统内存中把数据读到处理器缓存里。
* **总线风暴**：由于Volatile的MESI缓存一致性协议，需要**不断的从主内存嗅探和cas不断循环**，无效交互会导致**总线带宽达到峰值。**

* **禁止指令重排**
  
  * 为了提高性能，**编译器和处理器**常常会**对既定的代码执行顺序进行指令重排序。**
  * java编译器会**在生成指令系列**时在适当的位置会**插入`内存屏障`指令来禁止特定类型的处理器重排序。**
  * 为了实现volatile的内存语义，**JMM会限制特定类型的编译器和处理器重排序**，JMM会**针对编译器制定volatile重排序规则表：**
* 可见性保证：因为可见性，线程A在自己的内存初始化了对象，还没来得及写回主内存，B线程也这么做了，那就创建了多个对象，不是真正意义上的单例了。
* 总结：
  * volatile修饰符适用于以下场景：某个属性被多个线程共享，其中有一个线程修改了此属性，其他线程可以立即得到修改后的值，比如booleanflag;或者作为触发器，实现**轻量级同步。**
  * volatile属性的**读写操作都是无锁的**，它不能替代synchronized，因为它没有提供原子性和互斥性。因为无锁，不需要花费时间在获取锁和释放锁上，所以说它是低成本的。
  * volatile**只能作用于属性**，我们用volatile修饰属性，这样compilers就不会对这个属性做指令重排序。
  * volatile提供了**可见性**，任何一个线程对其的修改将立马对其他线程可见，volatile属性不会被线程缓存，始终从主 存中读取。
  * volatile提供了**happens-before**保证，对volatile变量 v 的写入 ，**happens-before ( 发生在读操作之前) 所有其他线程后续对v的读操作。**
  * volatile可以使得long和double的赋值是原子的。
  * volatile可以在单例双重检查中**实现可见性和禁止指令重排序**，从而保证安全性。

* CAS

  * 所谓的 CAS，其实是个简称，全称是 Compare And Swap，对比之后交换数据。上面的方法，有几个重要的参数：

    （1）this，Unsafe 对象本身，需要通过这个类来获取 value 的**内存偏移地址offset**。

    （2）valueOffset，value 变量的内存偏移地址。

    （3）expect，期望更新的值。

    （4）update，要更新的最新值。

    如果原子变量中的 value 值等于 expect，则使用 update 值更新该值并返回 true，否则返回 false。

### ThreadLocal

* 应用：

  * ThreadLocal的作用主要是做**数据隔离**，填充的数据只属于当前线程，变量的数据对别的线程而言是相对隔离的，在多线程环境下，防止自己的变量被其它线程篡改。

  * Spring通过**ThreadLocal和AOP实现事务隔离级别**。Spring采用Threadlocal的方式，来保证单个线程中的数据库操作使用的是同一个数据库连接，同时，采用这种方式可以使业务层使用事务时不需要感知并管理connection对象，通过传播行为，巧妙地管理多个事务配置之间的切换，挂起和恢复。

  * 使用SimpleDataFormat的parse()方法时，内部有一个Calendar对象，调用SimpleDataFormat的parse()方法会先调用Calendar.clear()，然后调用Calendar.add()，如果一个线程先调用了add() 然后另一个线程又调用了clear()，这时候parse()方法解析的时间就不对了。‘

    * 解决：使用线程池加上ThreadLocal包装`SimpleDataFormat`，再调用initialValue让每个线程有一个`SimpleDataFormat`的副本，从而解决了线程安全的问题，’

  * 项目中存在一个线程经常遇到横跨若干方法调用，需要传递的对象，也就是上下文（Context），它是一种状态，经常就是是用户身份、任务信息等，就会存在过渡传参的问题。

    当使用到类似责任链模式，给每个方法增加一个context参数非常麻烦，而且有些时候，如果调用链有无法修改源码的第三方库，对象参数就传不进去了，所以我使用到了ThreadLocal去做了一下改造，这样只需要在调用前在ThreadLocal中设置参数，其他地方get一下就好了。

  * 很多场景的cookie，session等数据隔离都是通过ThreadLocal去做实现的。

* 原理：

  * set()：底层是ThreadLocalMap，是从当前线程Thread一个 **threadLocals 变量中获取的。**
  * 每个线程Thread都维护了自己的threadLocals变量，所以在每个线程创建ThreadLocal的时候，实际上数据是**存在自己线程Thread的threadLocals变量里面的**，别人没办法拿到，从而实现了隔离。

* 底层数据结构

  * ![image-20210318134625779](https://gitee.com/picgo-table/picgo-img/raw/master/image/image-20210318134625779.png)
  * 底层是每个Thread线程有一个数组ThreadLocals，数组每个entry元素中存放一个ThreadLocalMap，key-val分别是ThreadLocal和value，但未实现Map接口，而且他的Entry是继承WeakReference（弱引用）的，也没有看到HashMap中的next，所以不存在链表了。

  * 哈希冲突：
    * ThreadLocalMap在存储的时候会给每一个ThreadLocal对象一个threadLocalHashCode，在插入过程中，根据ThreadLocal对象的hash值，定位到table中的位置i，**int i = key.threadLocalHashCode & (len-1)**。
    * 然后会判断一下：如果当前位置是空的，就初始化一个Entry对象放在位置i上；
    * 如果位置i不为空，如果这个Entry对象的key正好是即将设置的key，那么就刷新Entry中的value；
    * 如果位置i的不为空，而且key不等于entry，那就找下一个空位置，直到为空为止。

* 内存泄露

  * 弱引用：只具有弱引用的对象拥有更短暂的生命周期，在垃圾回收器线程扫描它所管辖的内存区域的过程中，一旦发现了只具有弱引用的对象，不管当前内存空间足够与否，都会回收它的内存。

  * ThreadLocal在没有外部强引用时，发生GC时会被回收，如果创建ThreadLocal的线程一直持续运行，那么这个Entry对象中的value就有可能一直得不到回收，发生内存泄露。

  * 解决：在使用的最后用remove把值清空就好了。找到对应的值全部置空，这样在垃圾回收器回收的时候，会自动把他们回收掉。

    

    

    
  















