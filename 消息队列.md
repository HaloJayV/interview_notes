### 消息队列基础

![image-20210326150854105](https://gitee.com/picgo-table/picgo-img/raw/master/image/image-20210326150854105.png)

* **01.优先级队列**
  
  优先级队列不同于先进先出队列，优先级高的消息具备优先被消费的特权，这样可以为下游提供不同消息级别的保证。不过这个优先级也是需要有一个前提的：如果消费者的消费速度大于生产者的速度，并且消息中间件服务器(一般简单的称之为Broker)中没有消息堆积，那么对于发送的消息设置优先级也就没有什么实质性的意义了，因为生产者刚发送完一条消息就被消费者消费了，那么就相当于Broker中至多只有一条消息，对于单条消息来说优先级是没有什么意义的。
  
  **02.延迟队列**
  
  当你在网上购物的时候是否会遇到这样的提示：“三十分钟之内未付款，订单自动取消”?这个是延迟队列的一种典型应用场景。延迟队列存储的是对应的延迟消息，所谓“延迟消息”是指当消息被发送以后，并不想让消费者立刻拿到消息，而是等待特定时间后，消费者才能拿到这个消息进行消费。延迟队列一般分为两种：基于消息的延迟和基于队列的延迟。基于消息的延迟是指为每条消息设置不同的延迟时间，那么每当队列中有新消息进入的时候就会重新根据延迟时间排序，当然这也会对性能造成极大的影响。实际应用中大多采用基于队列的延迟，设置不同延迟级别的队列，比如5s、10s、30s、1min、5mins、10mins等，每个队列中消息的延迟时间都是相同的，这样免去了延迟排序所要承受的性能之苦，通过一定的扫描策略(比如定时)即可投递超时的消息。
  
  **03.死信队列**
  
  **由于某些原因消息无法被正确的投递**，为了确保消息不会被无故的丢弃，一般将其置于一个特殊角色的队列，这个队列一般称之为死信队列。与此对应的还有一个“回退队列”的概念，试想如果消费者在消费时发生了异常，那么就不会对这一次消费进行确认(Ack),进而发生回滚消息的操作之后消息始终会放在队列的顶部，然后不断被处理和回滚，导致队列陷入死循环。为了解决这个问题，可以为每个队列设置一个回退队列，它和死信队列都是**为异常的处理提供的一种机制保障**。实际情况下，回退队列的角色可以由死信队列和重试队列来扮演。
  
  **04.重试队列**

  重试队列其实可以看成是一种回退队列，具体指消费端消费消息失败时，为防止消息无故丢失而重新将消息回滚到Broker中。与回退队列不同的是重试队列一般分成多个重试等级，每个重试等级一般也会设置重新投递延时，重试次数越多投递延时就越大。举个例子：消息第一次消费失败入重试队列Q1，Q1的重新投递延迟为5s，在5s过后重新投递该消息;如果消息再次消费失败则入重试队列Q2，Q2的重新投递延迟为10s，在10s过后再次投递该消息。以此类推，重试越多次重新投递的时间就越久，为此需要设置一个上限，超过投递次数就入死信队列。重试队列与延迟队列有相同的地方，都是需要设置延迟级别，它们彼此的区别是：延迟队列动作由内部触发，重试队列动作由外部消费端触发;延迟队列作用一次，而重试队列的作用范围会向后传递。
  
  **05.消费模式之推模式push**
  
  对于kafka而言，由Broker主动推送消息至消费端，实时性较好，不过需要一定的流制机制来确保服务端推送过来的消息不会压垮消费端。
  
  **06.消费模式之拉模式pull**
  
  对于kafka而言，消费端主动向Broker端请求拉取(一般是定时或者定量)消息，实时性较推模式差，但是可以根据自身的处理能力而控制拉取的消息量。
  
  **07.消息回溯**
  
  一般消息在消费完成之后就被处理了，之后再也不能消费到该条消息。消息回溯正好相反，是指消息在消费完成之后，还能消费到之前被消费掉的消息。对于消息而言，经常面临的问题是“消息丢失”，至于是真正由于消息中间件的缺陷丢失还是由于使用方的误用而丢失一般很难追查，如果消息中间件本身具备消息回溯功能的话，可以通过回溯消费复现“丢失的”消息进而查出问题的源头之所在。消息回溯的作用远不止与此，比如还有索引恢复、本地缓存重建，有些业务补偿方案也可以采用回溯的方式来实现。
  
  **08.消息堆积**
  
  流量削峰是消息中间件的一个非常重要的功能，而这个功能其实得益于其消息堆积能力。从某种意义上来讲，如果一个消息中间件不具备消息堆积的能力，那么就不能把它看做是一个合格的消息中间件。消息堆积分内存式堆积和磁盘式堆积。
  
  **09.消息追踪/轨迹**
  
  对于分布式架构系统中的链路追踪(trace)而言，大家一定不会陌生。对于消息中间件而言，消息的链路追踪(以下简称消息追踪)同样重要。对于消息追踪最通俗的理解就是要知道消息从哪来，存在哪里以及发往哪里去。基于此功能下，我们可以对发送或者消费完的消息进行链路追踪服务，进而可以进行问题的快速定位与排查。想要知道消息发送成功了吗?发送的消息在消费端为什么消费不到?为什么又会重复消费?等等问题。引入消息轨迹可以知道消息从生产者触发，经由broker等代理存储，再到消费者消费的整个过程，各个节点的状态、时间、地点等数据汇聚而成完整的链路信息。
  
  **10.消息过滤**
  
  消息过滤是指按照既定的过滤规则为下游用户提供指定类别的消息。就以kafka而言，完全可以将不同类别的消息发送至不同的topic中，由此可以实现某种意义的消息过滤，或者Kafka还可以根据分区对同一个topic中的消息进行分类。不过更加严格意义上的消息过滤应该是对既定的消息采取一定的方式按照一定的过滤规则进行过滤。同样以Kafka为例，可以通过客户端提供的ConsumerInterceptor接口或者Kafka Stream的filter功能进行消息过滤。对于rocketmq来说，支持Tag、SQL92和类过滤器(新版去除)等3种模式。
  
  **11.消息审计**
  
  消息审计是指在消息在生产、存储和消费的整个过程之间对消息个数及延迟的审计，以此来检测是否有数据丢失、是否有数据重复、端到端的延迟又是多少等。有关产品：Uber的Chaperone、LinkedIn的kafka monitor、Confluent Control Center等，有需要或感兴趣可自行通过网络了解下。
  
  **12.消息路由**
  
  将消息路由到指定的队列中，消费者消费队列里的消息。RabbitMQ可以从交换器Exchanger根据路由键路由到指定一个或多个队列。kafka默认是按照消息主题进行路由，消息路由在kafka中使用场景较少，使用起来也比较麻烦，如无特殊需要，一般不推荐使用。
  
* 重复消费
  
  * 就比如有这样的一个场景，用户下单成功后我需要去一个活动页面给他加**GMV**（销售总额），最后根据他的GMV去给他发奖励，这是电商活动很常见的玩法。类似累计下单金额到哪个梯度给你返回什么梯度的奖励这样。一般都是使用异步去实现
  * 一般消息队列的使用，我们都是有**重试机制**的，就是说我下游的业务发生异常了，我会抛出异常并且要求你**重新发一次**。
  * **别的服务也在监听**，他们也会失败啊，他一失败他也要求重发，但是你这里其实是成功的，重发了，你的钱不就加了两次了？
  * 解决：接口幂等（**无论多次执行，其结果都是一样的**）
    * 通俗了讲就是你**同样的参数调用我这个接口，调用多少次结果都是一个**，你加GMV同一个订单号你加一次是多少钱，你加N次都还是多少钱。
    * **分场景去考虑**，看是**强校验**还是**弱校验**，比如跟金钱相关的场景那就很关键呀，就做强校验，别不是很重要的场景做弱校验。
  * 强校验
    * **两个放在一个事务，成功一起成功失败一起失败**。
    * 每次消息过来都要拿着**订单号+业务场景这样的唯一标识**（比是天猫双十一活动）去流水表查，看看有没有这条流水，有就直接return不要走下面的流程了，没有就执行后面的逻辑。
    * ![image-20210326151902872](https://gitee.com/picgo-table/picgo-img/raw/master/image/image-20210326151902872.png)
  * 弱校验
  * 一些不重要的场景，比如给谁发短信啥的，我就把这个 **id+场景唯一标识 **作为**Redis**的key，放到缓存里面失效时间看你场景，**一定时间内**的这个消息就去Redis判断是否有该消息。
  
* 顺序消费
  * 生产者消费者一般需要保证顺序消息的话，可能就是一个业务场景下的，比如订单的创建、支付、发货、收货。
  * 一般都是**同个业务场景下不同几个操作的消息同时过去**，本身顺序是对的，但是你发出去的时候同时发出去了，消费的时候却乱掉了，这样就有问题了。
  * Rocket解决
    * **一个topic下有多个队列**，为了保证发送有序，**RocketMQ**提供了**MessageQueueSelector**队列选择机制，他有三种实现:
    * ![image-20210326155454713](https://gitee.com/picgo-table/picgo-img/raw/master/image/image-20210326155454713.png)
    * 可使用**Hash取模法**，让同一个订单发送到**同一个队列**中，再使用同步发送，只有同个订单的创建消息发送成功，再发送支付消息。这样，我们保证了发送有序。一个订单你发送的时候放到一个队列里面去，同一个订单号Hash一下还是一样的结果，那肯定是一个消费者消费
    * **RocketMQ**的topic内的队列机制,可以保证存储满足**FIFO**,   剩下的只需要消费者顺序消费即可。仅保证顺序发送，顺序消费由消费者业务保证
  * RabbitMQ解决：
    * ①拆分多个queue，每个queue一个consumer，就是多一些queue而已，确实是麻烦点；这样也会造成吞吐量下降，可以在消费者内部采用多线程的方式取消费。
    * ②或者就一个queue但是对应一个consumer，然后这个consumer内部用**多个内存队列做排队**，然后分发给底层不同的worker来处理
  * Kafka解决：
    * ①确保同一个消息发送到同一个partition，一个topic，一个partition，一个consumer，内部单线程消费。
    * ②写N个内存queue，然后**N个线程**分别消费一个内存queue即可

### RabbitMQ

* RabbitMQ 整体上是一个**生产者与消费者模型**，主要负责**接收、存储和转发消息**。可以把消息传递的过程想象成：当你将一个包裹送到邮局，邮局会暂存并最终将邮件通过邮递员送到收件人的手上，RabbitMQ就好比由邮局、邮箱和邮递员组成的一个系统。从计算机术语层面来说，RabbitMQ 模型更像是一种**交换机模型**。

* 模型

  * ![image-20210326170803960](https://gitee.com/picgo-table/picgo-img/raw/master/image/image-20210326170803960.png)

* 生产者消费者

  * 消息一般由 2 部分组成：**消息头**（或者说是标签 Label）和 **消息体**。消息体也可以称为 **payLoad** ,消息体是不透明的，而消息头则由一系列的可选属性组成，这些属性包括 **routing-key**（路由键）、**priority**（相对于其他消息的优先权）、**delivery-mode**（指出该消息可能需要持久性存储）等。生产者把消息交由 RabbitMQ 后，RabbitMQ 会根据消息头把消息发送给感兴趣的 Consumer(消费者)。

* 交换器Exchange

  * 在 RabbitMQ 中，消息并不是直接被投递到 **Queue(消息队列)** 中的，中间还必须经过 **Exchange(交换器)** 这一层，**Exchange(交换器)** 会把我们的消息分配到对应的 **Queue(消息队列)** 中。

    **Exchange(交换器)** 用来接收生产者发送的消息并将这些消息路由给服务器中的队列中，如果路由不到，或许会返回给 **Producer(生产者)** ，或许会被直接丢弃掉 。这里可以将RabbitMQ中的交换器看作一个简单的实体。

    **RabbitMQ 的 Exchange(交换器) 有4种类型，不同的类型对应着不同的路由策略**：**direct(默认)**，**fanout广播**, **topic**, 和 **headers**，不同类型的Exchange转发消息的策略有所区别。

  * 生产者将消息发给交换器的时候，一般会指定一个 **RoutingKey(路由键)**，用来指定这个消息的路由规则，而这个 RoutingKey 需要与交换器类型**和绑定键(BindingKey)联合使用**才能最终生效。

    RabbitMQ 中通过 **Binding(绑定)** 将 **Exchange(交换器)** 与 **Queue(消息队列)** 关联起来，在绑定的时候一般会指定一个 **BindingKey(绑定建)** , 这样 RabbitMQ 就知道如何**正确将消息路由到队列**了,  一个绑定就是**基于路由键将交换器和消息队列连接起来的路由规则**，所以可以将交换器理解成一个**由绑定构成的路由表**。Exchange 和 Queue 的绑定可以是**多对多**的关系。
    
  * ![image-20210401133230137](https://gitee.com/picgo-table/picgo-img/raw/master/image/image-20210401133230137.png)

* Binding：绑定Queue到Exchange中

  * 生产者将消息发送给交换器时，需要一个**RoutingKey**,  当 BindingKey 和 RoutingKey 相匹配时，消息会被**路由**到对应的队列中。在绑定多个队列到同一个交换器的时候，这些**绑定允许使用相同的 BindingKey**。BindingKey 并不是在所有的情况下都生效，它**依赖于交换器类型**，比如**fanout广播类型的交换器就会无视**，而是将消息**路由到所有绑定到该交换器的队列**中。

* Queue

  * **Queue(消息队列)** 用来**保存消息**直到发送给消费者。它是**消息的容器**，也是消息的终点。一个消息可投入一个或多个队列。消息一直在队列里面，等待消费者连接到这个队列将其取走。

    **RabbitMQ** 中消息只能存储在 **队列** 中，这一点和 **Kafka** 这种消息中间件相反。Kafka 将消息存储在 **topic（主题）** 这个逻辑层面，而相对应的队列逻辑只是**topic实际存储文件中的位移标识**。 RabbitMQ 的生产者生产消息并最终投递到队列中，消费者可以从队列中获取消息并消费。

    **多个消费者可以订阅同一个队列**，这时队列中的消息会被**平均分摊（Round-Robin，即轮询）**给多个消费者进行处理，而不是每个消费者都收到所有的消息并处理，这样**避免的消息被重复消费。**（解决重复消费）

    RabbitMQ **不支持队列层面的广播消费,**如果有广播消费的需求，需要在其上进行二次开发,这样会很麻烦，不建议这样做。

* Broker（消息中间件的**服务节点**）

  * 对于 RabbitMQ 来说，一个 RabbitMQ Broker 可以简单地看作一个 RabbitMQ 服务节点，或者RabbitMQ服务实例。大多数情况下也可以将一个 RabbitMQ Broker 看作一台 RabbitMQ 服务器。
  * ![image-20210326171620685](https://gitee.com/picgo-table/picgo-img/raw/master/image/image-20210326171620685.png)

* Exchange Types(交换器类型)

  * RabbitMQ 常用的 Exchange Type 有 **fanout**、**direct**、**topic**、**headers** 这四种（AMQP规范里还提到两种 Exchange Type，分别为 system 与 自定义，这里不予以描述）

    ##### ① fanout

    fanout 类型的Exchange路由规则非常简单，它会**把所有发送到该Exchange的消息路由到所有与它绑定的Queue**中，**不需要做任何判断**操作 (不需要用到Routing Key来路由)，所以 fanout 类型是所有的交换机类型里面速度最快的。fanout 类型常用来**广播消息**。

    ##### ② direct（最常用）

    direct 类型的Exchange路由规则也很简单，它会**把消息路由到那些 Bindingkey 与 RoutingKey 完全匹配的 Queue** 中。

    如果发送消息的时候设置路由键为“warning”, 那么消息会路由到 Queue1 和 Queue2。如果在发送消息的时候设置路由键为"Info”或者"debug”，消息只会路由到Queue2。如果以其他的路由键发送消息，则消息不会路由到这两个队列中。

    direct 类型常用在**处理有优先级的任务**，根据任务的优先级把消息发送到对应的队列，这样可以指派更多的资源去处理高优先级的队列。

  * ##### ③ topic

    前面讲到direct类型的交换器路由规则是完全匹配 BindingKey 和 RoutingKey ，但是这种严格的匹配方式在很多情况下不能满足实际业务的需求。topic类型的交换器在匹配规则上进行了扩展，它与 direct 类型的交换器相似，也是将消息路由到 BindingKey 和 RoutingKey 相匹配的队列中，但这里的匹配规则有些不同，它约定：

    - RoutingKey 为一个点号“．”分隔的字符串（被点号“．”分隔开的每一段独立的字符串称为一个单词），如 “com.rabbitmq.client”、“java.util.concurrent”、“com.hidden.client”;
    - BindingKey 和 RoutingKey 一样也是点号“．”分隔的字符串；
    - BindingKey 中可以存在两种特殊字符串“*”和“#”，用于做模糊匹配，其中“*”用于匹配一个单词，“#”用于匹配多个单词(可以是零个)。

  * #####  ④ headers(不推荐)

    headers 类型的交换器不依赖于路由键的匹配规则来路由消息，而是根据发送的消息内容中的 headers 属性进行匹配。在绑定队列和交换器时制定一组键值对，当发送消息到交换器时，RabbitMQ会获取到该消息的 headers（也是一个键值对的形式)'对比其中的键值对是否完全匹配队列和交换器绑定时指定的键值对，如果完全匹配则消息会路由到该队列，否则不会路由到该队列。headers 类型的交换器性能会很差，而且也不实用，基本上不会看到它的存在。
  
* AMQP协议：

  * ![image-20210401100155602](https://gitee.com/picgo-table/picgo-img/raw/master/image/image-20210401100155602.png)

  * 工作过程：

    * 发布者（Publisher）发布消息（Message），中间经由交换机（Exchange）

      交换机根据**路由规则**（bunding和routing key）将收到的消息分**发给与该交换机绑定的队列（Queue）**。

      最后 **AMQP 代理**会将消息投递给订阅了此队列的消费者，或者消费者按照需求自行获取。

  * 底层：

    * 1、发布者、交换机、队列、消费者都可以有多个。同时因为 AMQP 是一个网络协议，所以这个过程中的发布者，消费者，消息代理 可以分别存在于不同的设备上。

      2、发布者发布消息时可以给消息指定各种消息属性（Message Meta-data）。有些属性有可能会被消息代理（Brokers）使用，然而其他的属性则是完全不透明的，它们只能被接收消息的应用所使用。

      3、从安全角度考虑，网络是不可靠的，又或是消费者在处理消息的过程中意外挂掉，这样没有处理成功的消息就会丢失。基于此原因，AMQP 模块包含了一个消息确认（Message Acknowledgements）机制：当一个消息从队列中投递给消费者后，不会立即从队列中删除，直到它收到来自消费者的确认回执（Acknowledgement）后，才完全从队列中删除。

      4、在某些情况下，例如当一个消息无法被成功路由时（无法从交换机分发到队列），消息或许会被返回给发布者并被丢弃。或者，如果消息代理执行了延期操作，消息会被放入一个所谓的死信队列中。此时，消息发布者可以选择某些参数来处理这些特殊情况。

* RabbitMQ**消息确认机制（事务+confirm）**

  * ![image-20210401100501438](https://gitee.com/picgo-table/picgo-img/raw/master/image/image-20210401100501438.png)

  * 两种方式：
    * 1、通过**AMQP事务机制**实现，这也是AMQP协议层面提供的解决方案；
    * 2、通过**将channel设置成confirm模式**，即通过**发送方消息确认机制**来实现

  * 1、**AMQP**事务机制

    * RabbitMQ中与事务机制有关的方法有三个：**txSelect(), txCommit()以及txRollback(),** 
    * txSelect用于**将当前信道channel设置成事务transaction模式**，txCommit用于**提交事务**，txRollback用于**回滚事务**
    * 在通过txSelect开启事务之后，我们便可以**发布消息给broker**代理服务器（exchange+queue），如果txCommit提交成功了，则消息一定**到达了broker**了，如果在txCommit执行之前broker异常崩溃或者由于其他原因抛出异常，这个时候我们便可以捕获异常通过txRollback回滚事务了

  * 2、**confirm**模式  (发送方消息确认机制)

    * 生产者**将信道设置成confirm模式**，一旦信道进入confirm模式，所有在该信道channel上面发布的消息都会**被指派一个唯一的ID **(从1开始)，一旦消息被投递到所有匹配的队列之后，broker就会**发送一个确认给生产者**（包含消息的唯一**ID**）,这就使得生产者知道消息已经正确到达目的队列了

    * 如果消息和队列是可持久化的，那么confirm确认消息会将消息**写入磁盘之后发出**，broker回传给生产者的确认消息中**deliver-tag**域包含了确认消息的序列号，此外broker也可以设置basic.ack的multiple域，表示到这个序列号之前的所有消息都已经得到了处理。

      confirm模式最大的好处在于他是**异步**的，一旦发布一条消息，生产者应用程序就可以在等信道返回确认的同时继续发送下一条消息，当消息最终得到确认之后，生产者应用便可以通过**回调方法来处理该确认消息**，如果RabbitMQ因为自身内部错误导致消息丢失，就会发送一条nack（不确认）消息，生产者应用程序同样可以在回调方法中处理该nack消息。

      在channel 被设置成 confirm 模式之后，所有**被 publish 的后续消息都将被 confirm（即 ack）** 或者被nack一次。但是没有对消息被 confirm 的快慢做任何保证，并且同一条消息不会既被 confirm又被nack。

    * 开启confirm模式：

      * 生产者通过**调用channel的confirmSelect**方法将channel设置为confirm模式，如果没有设置no-wait标志的话，broker会返回 confirm.select-ok 表示同意发送者将当前channel信道设置为confirm模式 ，从目前RabbitMQ最新版本3.6来看，如果调用了channel.confirmSelect方法，默认情况下是直接将no-wait设置成false的，也就是默认情况下broker是必须回传confirm.select-ok

      * 对于固定消息体大小和线程数，如果消息持久化，生产者confirm(或者采用事务机制)，消费者ack那么对性能有很大的影响.

        消息持久化的优化没有太好方法，用更好的物理存储（SAS, SSD, RAID卡）总会带来改善。生产者confirm这一环节的优化则主要在于客户端程序的优化之上。归纳起来，客户端实现生产者confirm有三种编程方式：
    
        普通confirm模式：每发送一条消息后，调用waitForConfirms()方法，等待服务器端confirm。实际上是一种串行confirm了。
      批量confirm模式：每发送一批消息后，调用waitForConfirms()方法，等待服务器端confirm。
        异步confirm模式：提供一个回调方法，服务端confirm了一条或者多条消息后Client端会回调这个方法。

      * 为了保证消息从队列可靠地到达消费者，RabbitMQ提供消息确认机制(message acknowledgment)。消费者在声明队列时，可以指定noAck参数，当noAck=false时，RabbitMQ会等待消费者显式发回ack信号后才从内存(和磁盘，如果是持久化消息的话)中移去消息。否则，RabbitMQ会在队列中消息被消费后立即删除它。
    
        采用消息确认机制后，只要令noAck=false，消费者就有足够的时间处理消息(任务)，不用担心处理消息过程中消费者进程挂掉后消息丢失的问题，因为RabbitMQ会一直持有消息直到消费者显式调用basicAck为止。

* 死信队列
  
  * 死信队列介绍
  
    * 当消息在一个队列中变成一个死信（无法被消费的消息）之后，如果配置了死信队列，它将被**重新publish到死信交换机**，死信交换机**将死信投递到一个队列上**，这个队列就是死信队列。
    * 由于某些原因消息**无法被正确的投递**、**无法被消费者消费**，为了确保消息不会被无故的丢弃，一般将其置于一个特殊角色的队列，这个队列一般称之为死信队列。
  * 与此对应的还有一个“回退队列”的概念，试想如果消费者在消费时发生了异常，那么就**不会对这一次消费进行确认(Ack), 进而发生回滚消息**的操作之后**消息始终会放在队列的顶部**，然后不断被处理和回滚，导致队列陷入死循环。为了解决这个问题，可以为每个队列设置一个回退队列，它和死信队列都是为异常的处理提供的一种**机制保障**。实际情况下，回退队列的角色可以**由死信队列和重试队列来扮演。**
    
    * 死信交换机：**DLX**，`dead-letter-exchange`
  * 利用DLX，当消息在一个队列中变成死信 `(dead message)` 之后，它能**被重新publish到另一个Exchange**，这个Exchange就是DLX
    
    ###### 消息变成死信有以下几种情况
    
  - **消息被拒绝**(basic.reject / basic.nack)，并且 **requeue = false**
    - 消息**TTL**过期
  - **队列达到最大长度**
    
  * 死信机制实现延迟队列
  
    * 延迟队列存储的对象肯定是对应的延时消息，所谓”延时消息”是指当消息被发送以后，并不想让消费者立即拿到消息，而是等待指定时间后，消费者才拿到这个消息进行消费。
    * 第三方支付时，扫码支付调用上游的扫码接口，当扫码有效期过后去调用查询接口查询结果。实现方式：每当一笔扫码支付请求后，立即将此订单号放入延迟队列中（RabbitMQ），队列过期时间为二维码有效期，此队列没有设置消费者，**过了有效期后消息会重新路由到指定的的队列，有消费者去执行订单查询。**
    * RabbitMQ本身没有直接支持延迟队列功能，但是可以通过以下特性模拟出延迟队列的功能。 但是我们可以通过RabbitMQ的两个特性来曲线实现延迟队列：**Time To Live(TTL)**   和   **Dead Letter Exchanges（DLX）**
    * 所以在考虑使用RabbitMQ来实现延迟任务队列的时候，需要确保业务上每个任务的延迟时间是一致的。如果遇到不同的任务类型需要不同的延时的话，需要为每一种不同延迟时间的消息建立单独的消息队列。（也可以考虑缓存队列，DelayQueue实现定时延迟执行任务，但是也有缺点：就是项目重启缓存里的数据就会丢失
    * 延迟队列也可以结合**SpringTask**实现
  
    ###### 死信处理过程
  
    - DLX也是一个正常的Exchange，和一般的Exchange没有区别，它能在任何的队列上被指定，实际上就是**设置某个队列的属性。**
    - 当这个队列中有死信时，RabbitMQ就会自动的将这个消息**重新发布到设置的Exchange**上去，进而**被路由到另一个队列。**
    - 可以监听这个队列中的消息做相应的处理。
  
    ##### 死信队列设置
  
    1. 首先需要设置死信队列的exchange和queue，然后进行绑定：
  
    ```bash
    Exchange: dlx.exchange
    Queue: dlx.queue
    RoutingKey: #
    #表示只要有消息到达了Exchange，那么都会路由到这个queue上
    ```
  
    1. 然后需要有一个监听，去监听这个队列进行处理
    2. 然后我们进行正常声明交换机、队列、绑定，只不过我们需要在队列加上一个参数即可：`arguments.put(" x-dead-letter-exchange"，"dlx.exchange");`，这样消息在过期、requeue、 队列在达到最大长度时，消息就可以直接路由到死信队列！

### RocketMQ      

* RocketMQ事务消息机制
  
  * 事务可以抽象为：当一个表数据更新后，怎么保证另一个表的数据也必须要更新成功。
  
  * 如果是单机系统(数据库实例也在同一个系统上)的话，我们可以用**本地事务**轻松解决
  
  * 如果是分布式：采用2PC、3PC、TCC等
  
  * 使用RocketMQ：
  
    * 服务A完成业务后作为消费者产生一个消息到broker上，服务B消费即可，主要有两种保存消息的方式：
  
    * 1、支付宝在完成扣款的同时，同时记录消息数据，这个消息数据与业务数据保存在同一数据库实例里（消息记录表表名为message）。当上述事务提交成功后，我们通过实时消息服务将此消息通知余额宝，余额宝处理成功后发送回复成功消息，支付宝收到回复后删除该条消息数据。
  
    * 2、1）支付宝在扣款事务提交之前，向实时消息服务请求发送消息，实时消息服务只记录消息数据（未支付），而不真正发送，**只有消息发送成功后才会提交事务；**
  
      2）当支付宝扣款事务被提交成功后，向实时消息服务确认发送（已支付）。只有在得到确认发送指令后，实时消息服务才真正发送该消息；
  
      3）当支付宝扣款事务提交失败回滚后，向实时消息服务取消发送。在得到取消发送指令后，该消息将不会被发送；
  
      4）对于那些未确认的消息或者取消的消息，需要有一个消息状态确认系统定时去支付宝系统查询这个消息的状态并进行更新。为什么需要这一步骤，举个例子：假设在第2步支付宝扣款事务被成功提交后，系统挂了，此时消息状态并未被更新为“确认发送”，从而导致消息不能被发送。
  
* 核心模块

  * rocketmq-broker：接受生产者发来的消息并存储（通过调用rocketmq-store），消费者从这里取得消息
  * rocketmq-client：提供发送、接受消息的客户端API。
  * rocketmq-namesrv：NameServer，类似于Zookeeper，这里保存着消息的TopicName，队列等运行时的元信息。
  * rocketmq-common：通用的一些类，方法，数据结构等。
  * rocketmq-remoting：基于Netty4的client/server + fastjson序列化 + 自定义二进制协议。
  * rocketmq-store：消息、索引存储等。
  * rocketmq-filtersrv：消息过滤器Server，需要注意的是，要实现这种过滤，需要上传代码到MQ！（一般而言，我们利用Tag足以满足大部分的过滤需求，如果更灵活更复杂的过滤需求，可以考虑filtersrv组件）。
  * rocketmq-tools：命令行工具。

* NameServer

  * 主要负责对于**源数据的管理**，包括了对于**Topic**和**路由信息**的管理。

  * **NameServer**是一个功能齐全的服务器，其角色类似Dubbo中的Zookeeper，但NameServer与Zookeeper相比更轻量。主要是因为每个NameServer节点互相之间是独立的，没有任何信息交互。

    **NameServer**压力不会太大，平时主要开销是在**维持心跳和提供Topic-Broker**的关系数据。

    但有一点需要注意，Broker**向NameServer发心跳**时， 会带上当前自己所负责的所有**Topic**信息，如果Topic个数太多（万级别），会导致一次心跳中，Topic的数据就有几十M，网络情况差的话， 网络传输失败，心跳失败，导致NameServer误认为Broker心跳失败。

    **NameServer** 被设计成几乎**无状态**的，可以横向扩展，**节点之间相互之间无通信**，通过部署多台机器来标记自己是一个**伪集群**。

    每个 Broker 在启动的时候会到 NameServer 注册，Producer 在发送消息前会根据 Topic 到 **NameServer** 获取到 Broker 的路由信息，Consumer 也会**定时获取 Topic 的路由信息**。
    
  * NameService启动流程

    * 第一步是**初始化配置**
    * 创建**NamesrvController**实例，并**开启两个定时任务**：
    * 每隔10s扫描一次**Broker**，移除处于不激活的**Broker**；
    * 每隔10s**打印一次KV配置。**
    * 第三步注册钩子函数，启动服务器并**监听Broker。**

* producer
  * **Producer**由用户进行分布式部署，消息由**Producer**通过多种负载均衡模式发送到**Broker**集群，发送低延时，支持快速失败。
  * **RocketMQ** 提供了三种方式发送消息：同步、异步和单向
  * **同步发送**：同步发送指消息发送方发出数据后会在收到接收方发回响应之后才发下一个数据包。一般用于重要通知消息，例如重要通知邮件、营销短信。
  * **异步发送**：异步发送指发送方发出数据后，不等接收方发回响应，接着发送下个数据包，一般用于可能链路耗时较长而对响应时间敏感的业务场景，例如用户视频上传后通知启动转码服务。
  * **单向发送**：单向发送是指只负责发送消息而不等待服务器回应且没有回调函数触发，适用于某些耗时非常短但对可靠性要求并不高的场景，例如日志收集。
* 消息发送：通过轮询，**Producer**轮询某个**Topic**下面的所有队列实现发送方的负载均衡
  
* Broker
  * **消息中转角色**，负责**存储消息**，**转发消息**。
  
  * **Broker**是具体提供业务的服务器，单个Broker节点**与所有的NameServer节点保持长连接及心跳**，并会定时将**Topic**信息注册到NameServer，顺带一提底层的通信和连接都是**基于Netty实现**的。
  
  * **Broker**负责消息存储，以Topic为纬度支持轻量级的队列，单机可以支撑上万队列规模，支持**消息推拉模型**。
    
  * 官网上有数据显示：具有**上亿级消息堆积能力**，同时可**严格保证消息的有序性**。
  
  * 原理
  
    * **Broker**在RocketMQ中是进行**处理Producer发送消息的请求**，以及Consumer消费消息的请求，并且进行消息的持久化，以及**HA策略和服务端过滤**，就是集群中很重的工作都是交给了**Broker**进行处理。
  
      **Broker**模块是通过**BrokerStartup**进行启动的，会**实例化**BrokerController，并且调用其**初始化**方法
  
    * 初始化时会根据**配置创建很多线程池**主要用来**发送消息**、**拉取消息**、**查询消息**、**客户端管理**和**消费者管理**，也有很多**定时任务**，同时也注册了很多**请求处理器**，用来**发送拉取消息查询消息**的。 
  
* consumer
  * 消息消费者，负责消费消息，一般是后台系统负责异步消费。
  * **Consumer**也由用户部署，支持**PUSH和PULL**两种消费模式，支持**集群消费**和**广播消息**，提供**实时的消息订阅机制**。
  * **Pull**：拉取型消费者（Pull Consumer）主动从消息服务器拉取信息，只要批量拉取到消息，用户应用就会启动消费过程，所以 Pull 称为主动消费型。 
  * **Push**：推送型消费者（Push Consumer）封装了消息的拉取、消费进度和其他的内部维护工作，将消息到达时执行的回调接口留给用户应用程序来实现。所以 Push 称为被动消费类型，但从实现上看还是从消息服务器中拉取消息，不同于 Pull 的是 **Push 首先要注册消费监听器**，当监听器处触发后才开始消费消息。
* ![image-20210326185512618](https://gitee.com/picgo-table/picgo-img/raw/master/image/image-20210326185512618.png)
  
* 消息领域模型

  * ![image-20210326183107730](https://gitee.com/picgo-table/picgo-img/raw/master/image/image-20210326183107730.png)

  * Message

    **Message**（消息）就是要传输的信息。

    一条消息必须有一个主题（**Topic**），主题可以看做是你的信件要邮寄的地址。

    一条消息也可以拥有一个可选的标签（**Tag**）和额处的**键值对**，它们可以用于设置一个**业务 Key** 并在 Broker 上查找此消息以便在开发期间查找问题。

  * Topic

    **Topic**（主题）可以看做消息的规类，它是消息的第一级类型。比如一个电商系统可以分为：交易消息、物流消息等，一条消息必须有一个 Topic 。

    **Topic** 与生产者和消费者的关系非常松散，一个 Topic 可以有0个、1个、多个生产者向其发送消息，一个生产者也可以同时向不同的 Topic 发送消息。

    一个 Topic 也可以被 0个、1个、多个消费者订阅。

  * Tag

    **Tag**（标签）可以看作**子主题**，它是消息的第二级类型，用于为用户提供额外的灵活性。使用标签，同一业务模块不同目的的消息就可以用相同 Topic 而不同的 **Tag** 来标识。比如交易消息又可以分为：交易创建消息、交易完成消息等，一条消息可以没有 **Tag** 。

    标签有助于保持您的代码干净和连贯，并且还可以为 **RocketMQ** 提供的查询系统提供帮助。

  * Group

    分组，**一个组可以订阅多个Topic。**

    分为ProducerGroup，ConsumerGroup，代表某一类的生产者和消费者，一般来说同一个服务可以作为Group，同一个Group一般来说**发送和消费的消息都是一样的**

  * Queue

    在**Kafka**中叫Partition，每个Queue内部是有序的，在**RocketMQ**中分为**读和写两种队列**，一般来说**读写队列数量一致**，如果不一致就会出现很多问题。

  * Message Queue

    **Message Queue**（消息队列），主题被划分为一个或多个子主题，即消息队列。

    一个 Topic 下可以设置多个消息队列，发送消息时执行该消息的 Topic ，RocketMQ 会轮询该 Topic 下的所有队列将消息发出去。

    消息的物理管理单位。一个Topic下可以有多个Queue，Queue的引入使得消息的存储可以分布式集群化，具有了**水平扩展**能力。

  * Offset

    在**RocketMQ** 中，所有消息队列都是持久化，长度无限的数据结构，所谓长度无限是**指队列中的每个存储单元都是定长**，访问其中的存储单元使用Offset 来访问，Offset 为 java long 类型，64 位，理论上在 100年内不会溢出，所以认为是长度无限。

    也可以认为 Message Queue 是一个长度无限的数组，**Offset** 就是下标。

* 消息消费模式
  
  * 消息消费模式有两种：**Clustering**（集群消费）和**Broadcasting**（广播消费）。
  
    默认情况下就是集群消费，该模式下**一个消费者集群共同消费一个主题的多个队列**，**一个队列只会被一个消费者消费**，如果某个消费者挂掉，分组内其它消费者会接替挂掉的消费者继续消费。
  
    而广播消费消息会发给消费者组中的**每一个消费者进行消费。**
  
* 消费顺序Message Order：

  **Message Order**（消息顺序）有两种：**Orderly**（顺序消费）和**Concurrently**（并行消费）。

  顺序消费表示消息消费的顺序同生产者**为每个消息队列发送的顺序一致**，所以如果正在处理**全局顺序是强制性**的场景，需要确保使用的**主题只有一个消息队列。**

  并行消费不再保证消息顺序，消费的最大并行数量受每个消费者客户端指定的**线程池限制**。

* 通信流程

  * Producer 与 NameServer集群中的其中一个节点（随机选择）**建立长连接**，定期从 NameServer 获取 **Topic** 路由信息，并向提供 Topic 服务的 **Broker Master** 建立长连接，且定时向 **Broker** 发送心跳。

    **Producer** 只能将消息发送到 Broker master，但是 **Consumer** 则不一样，它同时和提供 Topic 服务的 Master 和 Slave建立长连接，既可以从 Broker Master 订阅消息，也可以从 Broker Slave 订阅消息。

* 消息去重

  * 去重原则：使用业务端逻辑保持幂等性

    **幂等性**：就是用户对于同一操作发起的一次请求或者多次请求的结果是一致的，不会因为多次点击而产生了副作用，数据库的结果都是唯一的，不可变的。

    只要保持幂等性，不管来多少条重复消息，最后处理的结果都一样，需要业务端来实现。

    **去重策略**：保证每条消息都有唯一编号(**比如唯一流水号)**，且保证**消息处理成功与去重表的日志同时出现**。

    建立一个消息表，拿到这个消息做数据库的insert操作。给这个消息做一个唯一主键（primary key）或者唯一约束，那么就算出现重复消费的情况，就会导致**主键冲突**，那么就不再处理这条消息。

* 优点

  * 单机吞吐量：十万级
  * 可用性：非常高，分布式架构
  * 消息可靠性：经过参数优化配置，消息可以做到0丢失
  * 功能支持：MQ功能较为完善，还是分布式的，扩展性好
  * 支持10亿级别的消息堆积，不会因为堆积导致性能下降

* 消息可用性

  * 当我们选择好了集群模式之后，那么我们需要关心的就是怎么去存储和复制这个数据，**RocketMQ**对**消息的刷盘提供了同步和异步**的策略来满足我们的，当我们选择同步刷盘之后，如果刷盘超时会给返回FLUSH_DISK_TIMEOUT，如果是异步刷盘不会返回刷盘相关信息，选择同步刷盘可以尽最大程度满足我们的消息不会丢失。

    除了存储有选择之后，我们的**主从同步**提供了同步和异步两种模式来进行复制，当然选择同步可以提升可用性，但是消息的发送RT时间会下降10%左右。

    **RocketMQ**采用的是混合型的存储结构，即为**Broker**单个实例下**所有的队列共用一个日志数据文件（即为CommitLog）**来存储。

    而**Kafka**采用的是独立型的存储结构，每个队列一个文件。

* 刷盘实现

  * **Broker** 在消息的存取时**直接操作的是内存**（内存映射文件），这可以提供系统的吞吐量，但是无法避免机器掉电时数据丢失，所以需要持久化到磁盘中。  

    刷盘的最终实现都是使用**NIO**中的 MappedByteBuffer.force() **将映射区的数据写入到磁盘**，如果是同步刷盘的话，在**Broker**把消息写到**CommitLog**映射区后，就会等待写入完成。

    异步而言，只是唤醒对应的线程，不保证执行的时机

* 顺序消息

  * **一个topic下有多个队列**，为了保证发送有序，**RocketMQ**提供了**MessageQueueSelector**队列选择机制，他有三种实现:

  * 我们可使用**Hash取模法**，让同一个订单发送到同一个队列中，再使用同步发送，只有同个订单的创建消息发送成功，再发送支付消息。这样，我们保证了发送有序。

    **RocketMQ**的topic内的队列机制,可以保证存储满足**FIFO**（First Input First Output 简单说就是指先进先出）,剩下的只需要消费者顺序消费即可。

    **RocketMQ**仅保证顺序发送，顺序消费由消费者业务保证!!!

* 分布式事务

  * 半消息

    * **是指暂不能被Consumer消费的消息**。Producer 已经把消息成功发送到了 Broker 端，但此消息被标记为`暂不能投递`状态，处于该种状态下的消息称为半消息。需要 Producer

      对消息的`二次确认`后，Consumer才能去消费它。

  * 消息回查

    * 由于网络闪段，生产者应用重启等原因。导致 **Producer** 端一直没有对 **Half Message(半消息)** 进行 **二次确认**。这时**Brock**服务器会定时扫描`长期处于半消息的消息`，会主动询问 **Producer**端 该消息的最终状态(**Commit或者Rollback**),该消息即为 **消息回查**。
    * ![image-20210326191250190](https://gitee.com/picgo-table/picgo-img/raw/master/image/image-20210326191250190.png)
    * A服务先发送个**Half Message**给Brocker端，消息中携带 B服务 **即将要+100元**的信息。
    * 当A服务知道Half Message发送成功后，那么开始第3步**执行本地事务**。
    * 执行本地事务(会有三种情况1、执行成功。2、执行失败。3、网络等原因导致没有响应)
    * 如果本地事务成功，那么Product像Brock服务器发送Commit,这样B服务就可以消费该message。
    * 如果本地事务失败，那么Product像Brock服务器发送Rollback,那么就会直接删除上面这条半消息。
    * 如果因为网络等原因迟迟没有返回失败还是成功，那么会执行RocketMQ的回调接口,来进行事务的回查。

* 消息过滤
  * **Broker**端消息过滤　　
    在**Broker**中，按照**Consumer**的要求做过滤，优点是减少了对于**Consumer**无用消息的网络传输。缺点是增加了Broker的负担，实现相对复杂。
  * **Consumer**端消息过滤
    这种过滤方式可由应用完全自定义实现，但是缺点是很多无用的消息要传输到**Consumer**端。

* Broker的Buffer问题

  * Broker的**Buffer**通常指的是Broker中一个队列的内存Buffer大小，这类**Buffer**通常大小有限。

    另外，RocketMQ没有内存**Buffer**概念，RocketMQ的队列都是持久化磁盘，数据定期清除。

    RocketMQ同其他MQ有非常显著的区别，RocketMQ的内存**Buffer**抽象成一个无限长度的队列，不管有多少数据进来都能装得下，这个无限是有前提的，Broker会定期删除过期的数据。

    例如Broker只保存3天的消息，那么这个**Buffer**虽然长度无限，但是3天前的数据会被从队尾删除。

* 回溯消息

  * 回溯消费是指Consumer已经消费成功的消息，由于业务上的需求需要重新消费，要支持此功能，Broker在向Consumer投递成功消息后，消息仍然需要保留。并且重新消费一般是按照时间维度。

    例如由于Consumer系统故障，恢复后需要重新消费1小时前的数据，那么Broker要提供一种机制，可以按照时间维度来回退消费进度。

    **RocketMQ**支持按照时间回溯消费，时间维度精确到毫秒，可以向前回溯，也可以向后回溯。

* 消息堆积
  * 消息中间件的主要功能是异步解耦，还有个重要功能是挡住前端的数据洪峰，保证后端系统的稳定性，这就要求消息中间件具有一定的消息堆积能力，消息堆积分以下两种情况：
    - 消息堆积在内存**Buffer**，一旦超过内存**Buffer**，可以根据一定的丢弃策略来丢弃消息，如CORBA Notification规范中描述。适合能容忍丢弃消息的业务，这种情况消息的堆积能力主要在于内存**Buffer**大小，而且消息堆积后，性能下降不会太大，因为内存中数据多少对于对外提供的访问能力影响有限。
    - 消息堆积到持久化存储系统中，例如DB，KV存储，文件记录形式。当消息不能在内存Cache命中时，要不可避免的访问磁盘，会产生大量读IO，读IO的吞吐量直接决定了消息堆积后的访问能力。
  * 评估消息堆积能力主要有以下四点：
  * 消息能堆积多少条，多少字节？即消息的堆积容量。
  * 消息堆积后，发消息的吞吐量大小，是否会受堆积影响？
  * 消息堆积后，正常消费的Consumer是否会受影响？
  * 消息堆积后，访问堆积在磁盘的消息时，吞吐量有多大？

* 定时消息

  * 定时消息是指消息发到**Broker**后，不能立刻被**Consumer**消费，要到特定的时间点或者等待特定的时间后才能被消费。

    如果要支持任意的时间精度，在**Broker**层面，必须要做消息排序，如果再涉及到持久化，那么消息排序要不可避免的产生巨大性能开销。

    **RocketMQ**支持定时消息，但是不支持任意时间精度，支持特定的level，例如定时5s，10s，1m等。

### Kafka

* 为了提高一个队列(topic)的**吞吐量**，Kafka会把topic进行分区(**Partition**)
* 一台Kafka服务器叫做**Broker**，Kafka集群就是多台Kafka服务器：
* 一个topic会分为多个partition，实际上partition会**分布**在不同的broker中
* 数据存在不同的partition上，那kafka就把这些partition做**备份**。比如，现在我们有三个partition，分别存在三台broker上。每个partition都会备份，这些备份散落在**不同**的broker上。
* ![image-20210326164625901](https://gitee.com/picgo-table/picgo-img/raw/master/image/image-20210326164625901.png)
* 红色块的partition代表的是**主**分区，紫色的partition块代表的是**备份**分区。生产者往topic丢数据，是与**主**分区交互，消费者消费topic的数据，也是与主分区交互。
* **备份分区仅仅用作于备份，不做读写。**如果某个Broker挂了，那就会选举出其他Broker的partition来作为主分区，这就实现了**高可用**。
* 持久化：
  * Kafka是将partition的数据写在**磁盘**的(消息日志)，不过Kafka只允许**追加写入**(顺序访问)，避免缓慢的随机 I/O 操作。
  * Kafka也不是partition一有数据就立马将数据写到磁盘上，它会先**缓存**一部分，等到足够多数据量或等待一定的时间再批量写入(flush)。

* 消费partition

  * 生产者可以有多个，消费者也可以有多个，一个消费者消费三个分区的数据。多个消费者可以组成一个**消费者组**。
  * 本来是一个消费者消费三个分区的，现在我们有消费者组，就可以**每个消费者去消费一个分区**（也是为了提高吞吐量）
  * ![image-20210326165341149](C:/Users/qq285/AppData/Roaming/Typora/typora-user-images/image-20210326165341149.png)
  * 如果消费者组中的某个消费者挂了，那么其中一个消费者可能就要消费两个partition了
  * 如果只有三个partition，而消费者组有4个消费者，那么一个消费者会空闲
  * 如果多加入一个**消费者组**，无论是新增的消费者组还是原本的消费者组，都能消费topic的全部数据。（消费者组之间从逻辑上它们是**独立**的）
  * 生产者往topic里丢数据是存在partition上的，而partition持久化到磁盘是IO顺序访问的，并且是先写缓存，隔一段时间或者数据量足够大的时候才批量写入磁盘的。
  * 消费者在读的时候也很有讲究：正常的读磁盘数据是需要将内核态数据拷贝到用户态的，而Kafka 通过调用`sendfile()`直接从内核空间（DMA的）到内核空间（Socket的），**少做了一步拷贝**的操作。也就是零拷贝

* 回溯

  * Kafka就是用`offset`来表示消费者的消费进度到哪了，每个消费者会都有自己的`offset`。说白了`offset`就是表示消费者的**消费进度**。

    在以前版本的Kafka，这个`offset`是由Zookeeper来管理的，后来Kafka开发者认为Zookeeper不合适大量的删改操作，于是把`offset`在broker以内部topic(`__consumer_offsets`)的方式来保存起来。

  * 每次消费者消费的时候，都会提交这个`offset`，Kafka可以让你选择是自动提交还是手动提交。

  * Zookeeper虽然在新版的Kafka中没有用作于保存客户端的`offset`，但是Zookeeper是Kafka一个重要的依赖：
    * 探测broker和consumer的添加或移除。
    * 负责维护所有partition的领导者/从属者关系（主分区和备份分区），如果主分区挂了，需要选举出备份分区作为主分区。
    * 维护topic、partition等元配置信息

* 保证消息有序

  * Kafka会将数据写到partition，单个partition的写入是有顺序的。如果要保证全局有序，那只能写入一个partition中。如果要消费也有序，消费者也只能有一个。





























