### 进程调度算法

* 也称 CPU 调度算法，毕竟进程是由 CPU 调度的。当 CPU 空闲时，操作系统就选择内存中的某个「就绪状态」的进程，并给其分配 CPU。
* 1、当进程从运行状态转到等待状态；
* 2、当进程从运行状态转到就绪状态；
* 3、当进程从等待状态转到就绪状态；
* 4、当进程从运行状态转到终止状态；
* 其中发生在 1 和 4 两种情况下的调度称为「非抢占式调度」，2 和 3 两种情况下发生的调度称为「抢占式调度」。
* 抢占的原则一般有三种，分别是时间片原则、优先权原则、短作业优先原则。
* 1、FCFS先来先服务调度算法：
  * **每次从就绪队列选择最先进入队列的进程，然后一直运行，直到进程退出或被阻塞，才会继续从队列中选择第一个进程接着运行。**
  * 但是当一个长作业先运行了，那么后面的短作业等待的时间就会很长，不利于短作业。
  * FCFS 对长作业有利，适用于 CPU 繁忙型作业的系统，而不适用于 I/O 繁忙型作业的系统。
* 2、SLF最短作业优先调度算法
  * **优先选择运行时间最短的进程来运行**，这有助于提高系统的**吞吐量**
  * 一个长作业在就绪队列等待运行，而这个就绪队列有非常多的短作业，那么就会使得长作业不断的往后推，周转时间变长，致使长作业长期不会被运行。
* 3、HRRN高响应比优先调度算法
  * 主要是权衡了短作业和长作业。公式：优先权 = 1 + 已经等待时间 / 任务时间
  * **每次进行进程调度时，先计算「响应比优先级」，然后把「响应比优先级」最高的进程投入运行**
  * 如果两个进程的「等待时间」相同时，「要求的服务时间」越短，「响应比」就越高，这样短作业的进程容易被选中运行；
  * 如果两个进程「要求的服务时间」相同时，「等待时间」越长，「响应比」就越高，这就**兼顾到了长作业进程**，因为进程的响应比可以随时间等待的增加而提高，当其等待时间足够长时，其响应比便可以升到很高，从而获得运行的机会；
* 4、RR时间片轮转调度算法
  * 最古老、最简单、最公平且使用最广的算法
  * **每个进程被分配一个时间段，称为时间片（Quantum），即允许该进程在该时间段中运行。**
  * 通常时间片设为 `20ms~50ms` 通常是一个比较合理的折中值。
* 5、HPF最高优先级调度算法
  * 调度程序能**从就绪队列中选择最高优先级的进程进行运行**。分为静态和动态优先级。**可能会导致低优先级的进程永远不会运行。**
  * 静态优先级：创建进程时候，就已经确定了优先级了，然后整个运行时间优先级都不会变化；
  * 动态优先级：根据进程的动态变化调整优先级，比如如果**进程运行时间增加，则降低其优先级**，如果进程等待时间（就绪队列的等待时间）增加，则升高其优先级，也就是**随着时间的推移增加等待进程的优先级**。
* 6、多级反馈队列调度算法
  * 「时间片轮转算法」和「最高优先级算法」的综合和发展。
  * **「多级」表示有多个队列，每个队列优先级从高到低，同时优先级越高时间片越短。**
  * **「反馈」表示如果有新的进程加入优先级高的队列时，立刻停止当前正在运行的进程，转而去运行优先级高的队列；**
  * 设置了多个队列，赋予每个队列不同的优先级，每个**队列优先级从高到低**，同时**优先级越高时间片越短**；
  * 新的进程会被放入到第一级队列的末尾，按先来先服务的原则排队等待被调度，如果在第一级队列规定的时间片没运行完成，则将其转入到第二级队列的末尾，以此类推，直至完成；
  * 当较高优先级的队列为空，才调度较低优先级的队列中的进程运行。如果进程运行时，有新进程进入较高优先级的队列，则停止当前运行的进程并将其移入到原队列末尾，接着让较高优先级的进程运行；

### 内存置换算法

​	页面置换算法的功能是，**当出现缺页异常，需调入新页面而内存已满时，选择被置换的物理页面**，也就是说选择一个**物理页面换出到磁盘**，然后把需要访问的页面换入到物理页。算法目标则是，尽可能减少页面的换入换出的次数

* **最佳页面置换算法**（*OPT*）
  * 置换在**「未来」最长时间不访问**的页面
  * 算法实现需要计算内存中每个逻辑页面的「下一次」访问时间，然后比较，选择未来最长时间不访问的页面，进行置换
* **先进先出置换算法**（*FIFO*）：**选择在内存驻留时间很长的页面进行中置换**
* **最近最久未使用的置换算法**（*LRU*）：**选择最长时间没有被访问的页面进行置换**
* **时钟页面置换算法**（*Lock*）
  * 把所有的页面都保存在一个类似钟面的「环形链表」中，一个表针指向最老的页面。当发生缺页中断时，算法首先检查表针指向的页面：
* **最不常用置换算法**（*LFU*）：**当发生缺页中断时，选择「访问次数」最少的那个页面，并将其淘汰**。

### 磁盘调度算法

- 先来先服务算法：先到来的请求，先被服务。
- 最短寻道时间优先算法：优先选择**从当前磁头位置所需寻道时间最短的请求**
- 扫描算法：**磁头在一个方向上移动，访问所有未完成的请求，直到磁头到达该方向上的最后的磁道，才调换方向**
- 循环扫描算法：只有磁头朝某个特定方向移动时，才处理磁道访问请求，而**返回时直接快速移动至最靠边缘的磁道**，也就是复位磁头，这个过程是很快的，并且**返回中途不处理任何请求**，该算法的特点，就是**磁道只响应一个方向上的请求**。
- LOOK 与 C-LOOK 算法：磁头在每个方向上仅仅移动到最远的请求位置，然后立即**反向移动**，而不需要移动到磁盘的最始端或最末端，**反向移动的途中会响应请求**。

### 死锁

* 必要条件

  * **互斥条件**：进程要求对所分配的资源进行排它性控制，即在一段时间内某资源仅为一进程所占用。
    **请求和保持条件**：当进程因请求资源而阻塞时，对已获得的资源保持不放。
    **不剥夺条件**：进程已获得的资源在未使用完之前，不能剥夺，只能在使用完时由自己释放。
    **环路等待条件**：在发生死锁时，必然存在一个**进程--资源的环形链。**

* 预防死锁

  * 资源一次性分配：一次性分配所有资源，这样就不会再有请求了：（破坏请求条件）
    只要有一个资源得不到分配，也不给这个进程分配其他的资源：（破坏请保持条件）
    可剥夺资源：即当某进程获得了部分资源，但得不到其它资源，则释放已占有的资源（破坏不可剥夺条件）
    资源有序分配法：系统给每类资源赋予一个编号，**每一个进程按编号递增的顺序请求资源**，释放则相反（破坏环路等待条件）

* 避免死锁

  * 预防死锁的几种策略，会严重地损害系统性能。因此在避免死锁时，要施加较弱的限制，从而获得 较满意的系统性能。由于在避免死锁的策略中，允许进程动态地申请资源。因而，系统在进行资源分配之前预先计算资源分配的安全性。若此次分配不会导致系统进入不安全的状态，则将资源分配给进程；否则，进程等待。其中最具有代表性的避免死锁算法是银行家算法。
  * **银行家算法**：首先需要定义**状态和安全状态**的概念。系统的状态是当前给进程分配的资源情况。因此，状态包含两个向量Resource（系统中每种资源的总量）和Available（未分配给进程的每种资源的总量）及两个矩阵Claim（表示进程对资源的需求）和Allocation（表示当前分配给进程的资源）。安全状态是指至少有一个资源分配序列不会导致死锁。当进程请求一组资源时，假设同意该请求，从而改变了系统的状态，然后确定其结果是否还处于安全状态。如果是，同意这个请求；如果不是，阻塞该进程知道同意该请求后系统状态仍然是安全的。

* 检测死锁

  * 首先为每个进程和每个资源指定一个唯一的号码；

  * 然后建立资源分配表和进程等待表。

  * 1、**Jstack**命令

    jstack是java虚拟机自带的一种堆栈跟踪工具。jstack用于打印出给定的java进程ID或core file或远程调试服务的Java堆栈信息。 Jstack工具可以用于生成java虚拟机当前时刻的线程快照。线程快照是当前java虚拟机内每一条线程正在执行的方法堆栈的集合，生成线程快照的主要目的是定位线程出现长时间停顿的原因，如线程间死锁、死循环、请求外部资源导致的长时间等待等。 线程出现停顿的时候通过jstack来查看各个线程的调用堆栈，就可以知道没有响应的线程到底在后台做什么事情，或者等待什么资源。

    2、**JConsole**工具

    Jconsole是JDK自带的监控工具，在JDK/bin目录下可以找到。它用于连接正在运行的本地或者远程的JVM，对运行在Java应用程序的资源消耗和性能进行监控，并画出大量的图表，提供强大的可视化界面。而且本身占用的服务器内存很小，甚至可以说几乎不消耗。 

* 解决死锁

  * 剥夺资源：从其它进程剥夺足够数量的资源给死锁进程，以解除死锁状态；
  * 撤消进程：可以直接撤消死锁进程或撤消代价最小的进程，直至有足够的资源可用，死锁状态.消除为止；所谓代价是指优先级、运行代价、进程的重要性和价值等。


### 进程间通信IPC

* 1、**管道**

  * 匿名管道应用：redis的RDB和AOF持久化时，主线程会通过cow机制fork一个子线程进行持久化工作

  我们来看一条 Linux 的语句
  
  ```
netstat -tulnp | grep 8080
  ```

  学过 Linux 命名的估计都懂这条语句的含义，其中”|“是**管道**的意思，它的作用就是把前一条命令的输出作为后一条命令的输入。在这里就是把 netstat -tulnp 的输出结果作为 grep 8080 这条命令的输入。如果两个进程要进行通信的话，就可以用这种**管道**来进行通信了，并且我们可以知道这条**竖线**是没有名字的，所以我们把这种通信方式称之为**匿名管道**。

  并且这种通信方式是**单向**的，只能把第一个命令的输出作为第二个命令的输入，如果进程之间想要互相通信的话，那么需要创建两个管道。

  居然有匿名管道，那也意味着有**命名**管道，下面我们来创建一个命名管道。
  
  ```
mkfifo  test
  ```

  这条命令创建了一个名字为 test 的命名管道。

  接下来我们用一个进程向这个管道里面写数据，然后有另外一个进程把里面的数据读出来。
  
  ```
echo "this is a pipe" > test   // 写数据
  ```

  这个时候管道的内容没有被读出的话，那么这个命令就会一直停在这里，只有当另外一个进程把 test 里面的内容读出来的时候这条命令才会结束。接下来我们用另外一个进程来读取
  
  ```
cat < test  // 读数据
  ```

  我们可以看到，test 里面的数据被读取出来了。上一条命令也执行结束了。

  从上面的例子可以看出，管道的通知机制类似于**缓存**，就像一个进程把数据放在某个缓存区域，然后等着另外一个进程去拿，并且是管道是**单向传输的。**

  这种通信方式有什么缺点呢？显然，这种通信方式**效率低下**，你看，a 进程给 b 进程传输数据，只能等待 b 进程取了数据之后 a 进程才能返回。

  所以管道不适合频繁通信的进程。当然，他也有它的优点，例如比较简单，能够保证我们的数据已经真的被其他进程拿走了。我们平时用 Linux 的时候，也算是经常用。

  2、**消息队列**

  那我们能不能把进程的数据放在某个内存之后就马上让进程返回呢？无需等待其他进程来取就返回呢？
  
  答案是可以的，我们可以用**消息队列**的通信模式来解决这个问题，例如 a 进程要给 b 进程发送消息，只需要把消息放在对应的消息队列里就行了，b 进程需要的时候再去对应的
    消息队列里取出来。同理，b 进程要个 a 进程发送消息也是一样。这种通信方式也类似于**缓存**吧。
  
    这种通信方式有缺点吗？答是有的，如果 a 进程发送的数据占的内存比较大，并且两个进程之间的通信特别频繁的话，消息队列模型就不大适合了。因为 a 发送的数据很大的话，意味**发送消息（拷贝）**这个过程需要花很多时间来读内存。
  
    哪有没有什么解决方案呢？答是有的，请继续往下看。

  3、**共享内存**

  **共享内存**这个通信方式就可以很好着解决**拷贝**所消耗的时间了。

  这个可能有人会问了，每个进程不是有自己的独立内存吗？两个进程怎么就可以共享一块内存了？

  我们都知道，系统加载一个进程的时候，分配给进程的内存并不是**实际物理内存**，而是**虚拟内存空间**。那么我们可以**让两个进程各自拿出一块虚拟地址空间来，然后映射到相同的物理内存**中，这样，两个进程虽然有着独立的虚拟内存空间，但有一部分却是映射到相同的物理内存，这就完成了**内存共享**机制了。

  4、**信号量**

  * 信号量（Semaphore）是操作系统提供的一种**进程间常见的通信方式**，主要用来**协调并发程序对共享资源的访问**，操作系统可以保证对信号量操作的**原子性**。
  - 信号量由一个**共享整型变量 S 和两个原子操作 P、V 组成**，S 只能通过 P 和 V 操作来改变
  - P 操作：即请求资源，意味着 **S 要减 1**，如果 S <  0, 则表示没有资源了，此时线程要进入等待队列（同步队列）等待
  - V 操作:  即释放资源，意味着 **S 要加 1**， 如果 S <= 0，说明等待队列里有线程，此时S+1后就需要唤醒线程。
  

共享内存最大的问题是什么？没错，就是多进程竞争内存的问题，就像类似于我们平时说的**线程安全**问题。如何解决这个问题？这个时候我们的**信号量**就上场了。

信号量的本质就是一个计数器，用来实现进程之间的互斥与同步。例如信号量的初始值是 1，然后 a 进程来访问**内存1**的时候，我们就把信号量的值设为 0，然后进程b 也要来访问**内存1**的时候，看到信号量的值为 0 就知道已经有进程在访问**内存1**了，这个时候进程 b 就会访问不了**内存1**。所以说，信号量也是进程之间的一种通信方式。

  5、**Socket**

  上面我们说的共享内存、管道、信号量、消息队列，他们都是多个进程在一台主机之间的通信，那两个相隔几千里的进程能够进行通信吗？

  答是必须的，这个时候 Socket 这家伙就派上用场了，例如我们平时通过浏览器发起一个 http 请求，然后服务器给你返回对应的数据，这种就是采用 Socket 的通信方式了。

### 线程

* 线程资源：
  
  * 共享资源：进程代码段、进程的公有数据(利用这些共享的数据，线程很容易的实现相互之间的通讯)、进程打开的文件描述符、信号的处理器、进程的当前目录和进程用户ID与进程组ID。
  * 私有资源：线程TID、寄存器组的值、线程的堆栈、错误返回码、线程的信号屏蔽码、线程的优先级
  
* 线程通信

  * 1、**volatile关键字方式**

    volatile有两大特性，一是**可见性**，二是**有序性**，**禁止指令重排序**，其中**可见性就是可以让线程之间进行通信**。

    volatile语义**保证线程可见性**有两个原则保证

    - 所有volatile修饰的变量一旦**被某个线程更改**，**必须立即刷新到主内存**
    - 所有volatile修饰的变量在**使用之前必须重新读取主内存的值**

    如果将volatile关键字去掉，线程切换一定次数后将不能感知到flag的变化，最开始能感知是线程启动时间差的原因。

    2、**join方式**

    **join**其实合理理解成是**线程合并**，当在一个线程**调用另一个线程的join**方法时，当前**线程阻塞等待被调用join方法的线程执行完毕**才能继续执行，所以 join 的好处能够**保证线程的执行顺序**，但是如果调用线程的join方法其实已经**失去了并行的意义**，虽然存在**多个线程**，但是**本质上还是串行**的，最后join的实现其实是**基于等待通知机制的。**

    3、**等待/通知机制**

    等待通知机制是基于**wait和notify**，以及**condition 的 await 和 signal**方法来实现的，在一个线程内调用该线程锁对象的wait方法，线程将进入等待队列进行等待直到被通知或者被唤醒。

    **为什么要必须获取锁？**
    因为调用**wait**方法时，必须要**先释放锁**，如果**没有持有锁将会抛出异常。**

    4、**threadLocal方式**

    threadLocal方式的线程通信，不像以上三种方式是多个线程之间的通信，它更像是一个**线程内部的通信**，将**当前线程和一个map (key为当前线程thread，value为线程携带的值) 绑定**，在当前**线程内可以任意存取数据**，**减省了方法调用间参数的传递**。

* 线程同步方式
  * 通过Object的wait和notify
  * 通过Condition的awiat和signal
  * 通过一个阻塞队列
  * 通过两个阻塞队列
  * 通过**SynchronousQueue** 
  * 通过线程池的Callback回调
  * 通过同步辅助类**CountDownLatch**
  * 通过同步辅助类**CyclicBarrier**

### 内存管理

* 简单分为**连续分配管理方式**和**非连续分配管理方式**这两种。连续分配管理方式是指**为一个用户程序分配一个连续的内存空间**，常见的如 **块式管理** 。同样地，非连续分配管理方式允许一个程序使用的**内存分布在离散或者说不相邻的内存**中，常见的如**页式管理** 和 **段式管理**。

  1. **块式管理** ： 远古时代的计算机操系统的内存管理方式。将**内存分为几个固定大小的块**，每个块中**只包含一个进程**。如果**程序运行需要内存**的话，操作系统就**分配给它一块**，如果程序运行只需要很小的空间的话，分配的这块内存很大一部分几乎被浪费了。这些在**每个块中未被利用的空间**，我们称之为**碎片**。
  2. **页式管理** ：把主存分**为大小相等且固定的一页一页的形式**，页的空间较小，大小固定，相对相比于块式管理的**划分力度更大**，提高了**内存利用率**，**减少了碎片**。页式管理通过**页表对应逻辑地址和物理地址**。
  3. **段式管理** ： 页式管理虽然提高了内存利用率，但是页式管理其中的页实际并**无任何实际意义**。 段式管理把主存**分为一段段**的大小不固定，每一段的空间又要比一页的空间小很多 。但是，最重要的是段是**有实际意义**的，每个段**定义了一组逻辑信息**，例如,有**主程序段 MAIN、子程序段 X、数据段 D 及栈段 S** 等。 段式管理通过**段表对应逻辑地址和物理地址**
  4. **段页式管理**：段页式管理机制**结合了段式管理和页式管理**的优点。简单来说段页式管理机制就是**把主存先分成若干段（让其有实际意义）**，每个段又**分成若干页（加大划分力度）**，也就是说 **段页式管理机制** 中**段与段之间以及段的内部的都是离散**的。

* 快表和多级页表

  在**分页内存管理**中，很重要的两点是：

  1. **虚拟地址到物理地址的转换要快**。
  2. 解决**虚拟地址空间大，页表也会很大**的问题。

* 快表（时间局部性原理）

  为了**解决虚拟地址到物理地址的转换速度**，操作系统在 **页表方案** 基础之上引入了 **快表** 来**加速虚拟地址到物理地址的转换**。我们可以把快表理解为一种**特殊的高速缓冲存储器（Cache）**，其中的**内容**是**页表的一部分或者全部内容**。作为**页表的 Cache**，它的**作用与页表相似**，但是**提高了访问速率**。

  由于**采用页表做地址转换**，**读写内存数据**时 **CPU 要访问两次主存**。有了快表，有时**只要访问一次高速缓冲存储器**，**一次主存**，这样可**加速查找并提高指令执行速度**。

  使用快表之后的**地址转换流程**是这样的：

  1. **根据虚拟地址中的页号查快表**；
  2. 如果该页**在快表**中，直接**从快表中读取相应的物理地址**；
  3. 如果该页**不在快表**中，就**访问内存中的页表**，再**从页表中得到物理地址**，同时将**页表中的该映射表项添加到快表**中；
  4. 当**快表填满**后，又要**登记新页**时，就按照一定的**淘汰策略淘汰掉快表中的一个页**。

* 多级页表（空间局部性原理）

  引入多级页表的主要目的是为了**避免把全部页表一直放在内存中占用过多空间**，特别是那些根本就**不需要的页表就不需要保留在内存**中。多级页表属于**时间换空间**的典型场景

  为了**提高内存的空间性能**，提出了**多级页表**的概念；但是提高空间性能是以**浪费时间性能为基础**的，因此为了**补充损失的时间性能**，提出了**快表（即 TLB）**的概念。 不论是快表还是多级页表实际上都利用到了**程序的局部性原理**

* 局部性原理

  * **时间局部性**：如果一个信息项正在被访问，那么在近期它很可能还会被再次访问。
    这当然是正确的，用过的数据当然可能再次被用到。

    **空间局部性**：在最近的将来将用到的信息很可能与现在正在使用的信息在空间地址上是临近的。
    正在使用的这个数据地址旁边的数据，当然也是很可能被用到的。比如数组什么的

* 逻辑（虚拟）地址和物理地址

  我们编程一般只有可能和逻辑地址打交道，比如在 C 语言中，**指针里面存储的数值**就可以理解成为**内存里的一个地址**，这个地址也就是我们说的逻辑地址，逻辑地址由**操作系统决定**。物理地址指的是**真实物理内存中地址**，更具体一点来说就是**内存地址寄存器中的地址**。物理地址是**内存单元真正的地址**。一般页表保存的是逻辑地址和物理地址的映射关系，需要先根据虚拟地址的页号找到对应的页表，从该表得到物理地址。

* 分页机制和分段机制有哪些共同点和区别呢？

  1. **共同点**
     - 分页机制和分段机制都是为了**提高内存利用率，较少内存碎片**。
     - 页和段都是**离散存储**的，所以两者都是**离散分配内存**的方式。但是，每个页和段中的**内存是连续**的。
  2. **区别**
     - **页的大小是固定**的，由**操作系统决定**；而**段的大小不固**定，取决于我们**当前运行的程序**。
     - **分页**仅仅是为了**满足操作系统内存管理的需求**，而**段是逻辑信息的单位**，在程序中可以体现为**代码段，数据段**，能够更好满足用户的需要。

### 上下文切换

* 地址空间
  * 3G-4G大部分是共享的，是内核态的地址空间。这里存放整个内核的代码和所有的内核模块以及内核所维护的数据。

![image-20210331201914731](https://gitee.com/picgo-table/picgo-img/raw/master/image/image-20210331201914731.png)

* **特权级**

  * 对于任何操作系统来说，创建一个进程是核心功能。创建进程要做很多工作，会消耗很多物理资源。比如**分配物理内存，父子进程拷贝信息，拷贝设置页目录页表**等等，这些工作得由特定的进程去做，所以就有了特权级别的概念。
  * 最关键的工作必须交给**特权级最高的进程去执行**，这样可以做到**集中管理**，减少**有限资源的访问和使用冲突**。inter x86 (32bit )架构的cpu一共有四个级别，0-3级，0级特权级最高，3级特权级最低。低级进程不能访问高级进程的资源，而高级可以访问低级进程资源并管理

* 用户态、内核态

  * 当一个进程在执行用户自己的代码时处于用户**运行态（用户态）**，此时**特权级最低**，为3级，是普通的用户进程运行的特权级，大部分用户直接面对的程序都是运行在用户态。Ring3状态不能访问Ring0的地址空间，包括代码和数据
  * 当一个进程因为**系统调用陷入内核代码**中执行时处于内核运行态（**内核态**），此时**特权级最高**，为0级。执行的内核代码会**使用当前进程的内核栈**，每个进程都有自己的内核栈。

  * 用户运行一个程序，该程序创建的进程开始时运行自己的代码，处于用户态。如果要执行**文件操作、网络数据发送**等操作必须通过**write、send**等系统调用，这些**系统调用会调用内核的代码**。进程会切换到**Ring0  (进入内核态)**，然后进入3G-4G中的内核地址空间去执行内核代码来完成相应的操作。内核态的进程执行完后又会切换到Ring3（每次上下文切换2次），回到用户态。这样，用户态的程序就不能随意操作内核地址空间，具有一定的**安全保护作用**。这说的保护模式是指通过**内存页表操作**等机制，保证进程间的地址空间不会互相冲突，一个进程的操作不会修改另一个进程地址空间中的数据。

* 用户态和内核态的切换

  当在系统中执行一个程序时，大部分时间是运行在用户态下的，在其需要操作系统帮助完成一些用户态自己没有特权和能力完成的操作时就会切换到内核态。

  用户态切换到内核态的3种方式

  （1）**系统调用**

  这是用户态进程主动要求切换到内核态的一种方式。用户态进程通过系统调用申请使用操作系统提供的服务程序完成工作。例如fork（）就是执行了一个创建新进程的系统调用。系统调用的机制和新是使用了操作系统为用户特别开放的一个中断来实现，如Linux的int 80h中断。

  （2）**异常**

  当cpu在执行运行在用户态下的程序时，发生了一些没有预知的异常，这时会**触发由当前运行进程切换到处理此异常的内核相关进程中**，也就是切换到了内核态，如**缺页异常。**

  （3）**外围设备的中断**

  当外围设备完成用户请求的操作后，会向CPU发出相应的中断信号，这时CPU会暂停执行下一条即将要执行的指令而转到与中断信号对应的处理程序去执行，如果前面执行的指令时用户态下的程序，那么转换的过程自然就会是 由用户态到内核态的切换。如硬盘读写操作完成，系统会切换到硬盘读写的中断处理程序中执行后边的操作等。

  这三种方式是系统在运行时由用户态切换到内核态的最主要方式，其中系统调用可以认为是用户进程主动发起的，异常和外围设备中断则是被动的。从触发方式上看，切换方式都不一样，但从最终实际完成由用户态到内核态的切换操作来看，步骤有事一样的，都相当于执行了一个中断响应的过程。系统调用实际上最终是中断机制实现的，而异常和中断的处理机制基本一致。

* 用户态到内核态具体的切换步骤：

  （1）从当前进程的描述符中提取其内核栈的ss0及esp0信息。

  （2）使用ss0和esp0指向的内核栈将当前进程的cs,eip,eflags,ss,esp信息保存起来，这个过程也完成了由用户栈到内核栈的切换过程，同时保存了被暂停执行的程序的下一条指令。

  （3）将先前由中断向量检索得到的中断处理程序的cs,eip信息装入相应的寄存器，开始执行中断处理程序，这时就转到了内核态的程序执行了。
  
* 上下文切换：

  * CPU通过分配时间片来执行任务，当一个任务的时间片用完，就会切换到另一个任务。在切换之前会保存上一个任务的状态，当下次再切换到该任务，就会加载这个状态。
    **——任务从保存到再加载的过程就是一次上下文切换。**

  ![image-20210406095242120](https://gitee.com/picgo-table/picgo-img/raw/master/image/image-20210406095242120.png)


### 进程

* 进程资源共享问题
  * 进程是放到内存中的，进程中所有的计算过程都是需要在cpu处理的。当**有多个进程都需要使用共享资源**的时候就需要借助一个中间过程（“**临界区**”）
    临界区的使用原则：**“空则让进，忙则等待，等则有限，等则让权**”
    当共享资源没有被使用的时候就将某个需要使用的进程放到临界区中，在这段时间中只能是临界区中的进程可以使用共享资源。当共享资源在使用的时候，其他进程不能使用共享资源。共享资源空闲的时候就将其他等待使用共享资源的进程放到临界区中，但是如果等待的时间比较长久就先将等待的进程阻塞。
  * **临界区控制方式进程执行：**
    1.控制进入临界区（判断是否可以进入（临界区是否忙），如果可以就保护起来准备使用资源）
    2.临界区（使用资源）
    3.解除控制（临界区闲置）

**孤儿进程**

一个父进程退出，而它的一个或多个**子进程还在运行**，那么这些子进程将成为孤儿进程。

孤儿进程将被 **init 进程（进程号为 1）**所收养，并由 init 进程对它们完成**状态收集工作。**

由于孤儿进程会被 init 进程管理，所以孤儿进程不会对系统造成危害。

**僵尸进程**

一个**子进程的进程描述符**在子进程退出时不会释放，只有当**父进程通过 wait() 或 waitpid() 获取了子进程信息后才会释放**。如果子进程退出，而父进程并没有调用 wait() 或 waitpid()，那么**子进程的进程描述符**仍然保存在系统中，这种进程称之为僵尸进程。

僵尸进程通过 ps 命令显示出来的状态为 **Z（zombie）。**

系统所能使用的进程号是有限的，如果产生大量僵尸进程，将**因为没有可用的进程号**而导致系统不能产生新的进程。

要消灭系统中大量的僵尸进程，只需要**将其父进程杀死**，此时僵尸进程就会变成孤儿进程，从而被 init 所收养，这样 init 就会释放所有的僵尸进程所占有的资源，从而结束僵尸进程

**守护进程**

Linux Daemon（守护进程）是**运行在后台**的一种特殊孤儿进程。它**独立于控制终端**并且**周期性地执行某种任务或等待处理某些发生的事件**。它不需要用户输入就能运行而且提供某种服务，不是对整个系统就是对某个用户程序提供服务。Linux系统的**大多数服务器就是通过守护进程实现**的。常见的守护进程包括**系统日志进程syslogd、 web服务器httpd、邮件服务器sendmail和数据库服务器mysqld**等。

守护进程一般在**系统启动时开始运行**，除非强行终止，否则直到系统关机都保持运行。守护进程经常**以超级用户（root）权限运行**，因为它们要使用**特殊的端口（1-1024）**或访问某些特殊的资源。

一个守护进程的**父进程是init进程**，因为它真正的**父进程在fork出子进程后就先于子进程exit退出**了，所以它是一个**由init继承的孤儿进程**。守护进程是非交互式程序，没有控制终端，所以任何输出，无论是向标准输出设备stdout还是标准出错设备stderr的输出都需要特殊处理。

守护进程的名称通常以d结尾，比如**sshd、xinetd、crond**等













