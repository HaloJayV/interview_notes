### 分布式

* 分布式可以认为是**通过网络连接多个组件**而形成的系统。

  广义上说前后分离的应用就能算分布式，前端的 js 代码在浏览器跑着，后端的代码在服务器跑着，两种不同的组件合力对外提供服务构成分布式。

  而我们**常提到的分布式是狭义上的，指代不同的组件通过协作构成的系统**。

  而**集群常指的同一个组件多实例而构成逻辑上的整体**。

  这两个概念不冲突，分布式系统里面可以包含集群，像我们的商品服务就可以是集群部署。
  
* 消息队列

  * 对于MQ的作用大家都应该很了解了，削峰填谷、解耦。依赖消息队列，同步转异步的方式，可以降低微服务之间的耦合。

    对于一些不需要同步执行的接口，可以通过引入消息队列的方式异步执行以提高接口响应时间。在交易完成之后需要扣库存，然后可能需要给会员发放积分，本质上，发积分的动作应该属于履约服务，对实时性的要求也不高，我们只要保证最终一致性也就是能履约成功就行了。对于这种同类性质的请求就可以走MQ异步，也就提高了系统抗压能力了。

* 水平分表

  * 首先根据业务场景来决定使用什么字段作为分表字段(sharding_key)，比如我们现在日订单1000万，我们大部分的场景来源于C端，我们可以用user_id作为sharding_key，数据查询支持到最近3个月的订单，超过3个月的做归档处理，那么3个月的数据量就是9亿，可以分1024张表，那么每张表的数据大概就在100万左右。

    比如用户id为100，那我们都经过hash(100)，然后对1024取模，就可以落到对应的表上了。

* 分表后的ID唯一

  * 因为我们主键默认都是自增的，那么分表之后的主键在不同表就肯定会有冲突了。有几个办法考虑：
    1. 设定步长，比如1-1024张表我们分别设定1-1024的基础步长，这样主键落到不同的表就不会冲突了。
    2. 分布式ID，自己实现一套分布式ID生成算法或者使用开源的比如雪花算法这种
    3. 分表后不使用主键作为查询依据，而是每张表单独新增一个字段作为唯一主键使用，比如订单表订单号是唯一的，不管最终落在哪张表都基于订单号作为查询依据，更新也一样。

* 缓存热点Key

  * 提前把热key打散到不同的服务器，降低压力
  * 加入二级缓存，提前加载热key数据到内存中，如果redis宕机，走内存查询

* 高可用

  * **熔断**

    比如营销服务挂了或者接口大量超时的异常情况，不能影响下单的主链路，涉及到积分的扣减一些操作可以在事后做补救。

    **限流**

    对突发如大促秒杀类的高并发，如果一些接口不做限流处理，可能直接就把服务打挂了，针对每个接口的压测性能的评估做出合适的限流尤为重要。

    **降级**

    熔断之后实际上可以说就是降级的一种，以熔断的举例来说营销接口熔断之后降级方案就是短时间内不再调用营销的服务，等到营销恢复之后再调用。

    **预案**

    一般来说，就算是有统一配置中心，在业务的高峰期也是不允许做出任何的变更的，但是通过配置合理的预案可以在紧急的时候做一些修改。

    **核对**

    针对各种分布式系统产生的分布式事务一致性或者受到攻击导致的数据异常，非常需要核对平台来做最后的兜底的数据验证。比如下游支付系统和订单系统的金额做核对是否正确，如果收到中间人攻击落库的数据是否保证正确性。

* 如何设计高并发系统

  * 这个问题本身会带来更多的问题，微服务本身的拆分带来了分布式事务的问题，http、RPC框架的使用带来了通信效率、路由、容错的问题，MQ的引入带来了消息丢失、积压、事务消息、顺序消息的问题，缓存的引入又会带来一致性、雪崩、击穿的问题，数据库的读写分离、分库分表又会带来主从同步延迟、分布式ID、事务一致性的问题，而为了解决这些问题我们又要不断的加入各种措施熔断、限流、降级、离线核对、预案处理等等来防止和追溯这些问题。

### 分布式锁

* redis



### 微服务架构

* Restful
  
  * rest：基于HTTP、URI、XML、JSON等标准和协议，支持轻量级、跨平台、跨语言的架构设计。是Web服务的一种新的架构风格（一种思想）。
  * restful其实就是一套编写接口的协议，协议规定如何编写以及如何设置返回值、状态码等信息。
  * 给用户一个url，根据method不同在后端做不同的处理，比如：post 创建数据、get获取数据、put和patch修改数据、delete删除数据。
  
* 版本，来控制让程序有多个版本共存的情况，版本可以放在 url、请求头（accept/自定义）、GET参数
  
  * RESTful是一种常见的REST应用，是遵循REST风格的web服务，REST式的web服务是一种ROA（面向资源的架构）。
  
* MVC执行流程

  * 1.用户发送请求至**前端控制器DispatcherServlet**
     2.DispatcherServlet收到请求调用**处理器映射器HandlerMapping。**
     3.处理器映射器**根据请求url找到具体的处理器**，生成**处理器执行链HandlerExecutionChain**(包括处理器对象和处理器拦截器)一并返回给DispatcherServlet。
     4.DispatcherServlet根据处理器Handler**获取处理器适配器HandlerAdapter**执行HandlerAdapter处理一系列的操作，如：参数封装，数据格式转换，数据验证等操作
     5.执行处理器Handler(Controller，也叫页面控制器)。
     6.Handler执行完成返回ModelAndView
     7.HandlerAdapter将Handler执行结果ModelAndView返回到DispatcherServlet
     8.DispatcherServlet将ModelAndView传给ViewReslover视图解析器
     9.ViewReslover解析后返回具体View
     10.DispatcherServlet对View进行渲染视图（即将模型数据model填充至视图中）。
     11.DispatcherServlet响应用户。

* **系统的耦合度降低**，模块之间的边界清晰，都按业务物理隔离了。

  在一定的措施下（下文会提到），**系统整体可靠性变高**。

  **技术选型丰富，不同的服务可以利用不同的技术或语言实现**，例如数据分析服务可以用 Python 实现，一些底层的服务团队说我要用 GO，那就用 GO 呗。

  **可根据服务扩展部署**，商品服务访问量特大，那我们就单单给商品服务扩容，增加机器，其他服务照旧。

* SOA，全称 `Service-Oriented Architecture`即面向服务的架构。说到SOA就离不开 ESB，全称`Enterprise Service Bus`。SOA和微服务一样都是面向服务的。

* 其实我们可以抓到关键字企业，**SOA 我认为是企业级别的面向服务概念，而微服务是应用级别的概念**。

  两种都是面向服务，只是 **SOA 注重的是企业资源的重复利用，把企业的各个应用通过 ESB 进行整合。**

  **而微服务注重的是应用级别的服务划分，使得应用内服务边界清晰，易扩展**。

### 性能指标

通常是以 4 个指标来衡量网络的性能，分别是带宽、延时、吞吐率、PPS

* *带宽*，表示链路的最大传输速率，单位是 b/s （比特 / 秒），带宽越大，其传输能力就越强。
* *延时*，表示请求数据包发送后，收到对端响应，所需要的时间延迟。不同的场景有着不同的含义，比如可以表示建立 TCP 连接所需的时间延迟，或一个数据包往返所需的时间延迟。
* *吞吐率*，表示单位时间内成功传输的数据量，单位是 b/s（比特 / 秒）或者 B/s（字节 / 秒），吞吐受带宽限制，带宽越大，吞吐率的上限才可能越高。
* *PPS*，全称是 Packet Per Second（包 / 秒），表示以网络包为单位的传输速率，一般用来评估系统对于网络的转发能力。
* *网络的可用性*，表示网络能否正常通信；
* *并发连接数*，表示 TCP 连接数量；
* *丢包率*，表示所丢失数据包数量占所发送数据组的比率；
* *重传率*，表示重传网络包的比例；

### 负载均衡

* 硬件：成本比较高，并发数在百万级别，比如F5;

* 反向代理器-负载均衡算法：

  * **1、轮询法**

    　　将请求按顺序轮流地分配到后端服务器上，它均衡地对待后端的每一台服务器，而不关心服务器实际的连接数和当前的系统负载。

    **2、随机法**

       通过系统的随机算法，根据后端服务器的列表大小值来随机选取其中的一台服务器进行访问。由概率统计理论可以得知，随着客户端调用服务端的次数增多，其实际效果越来越接近于平均分配调用量到后端的每一台服务器，也就是轮询的结果。

    **3、源地址哈希法**

       源地址哈希的思想是根据获取客户端的IP地址，通过哈希函数计算得到的一个数值，用该数值**对服务器列表的大小进行取模运算**，得到的结果便是客服端要访问服务器的序号。采用源地址哈希法进行负载均衡，同一IP地址的客户端，当后端服务器列表不变时，它每次都会映射到同一台后端服务器进行访问。

    **4、加权轮询法**

    　　不同的后端服务器可能机器的配置和当前系统的负载并不相同，因此它们的抗压能力也不相同。给配置高、负载低的机器配置更高的权重，让其处理更多的请；而配置低、负载高的机器，给其分配较低的权重，降低其系统负载，加权轮询能很好地处理这一问题，并将请求顺序且按照权重分配到后端。

    **5、加权随机法**

       与加权轮询法一样，加权随机法也根据后端机器的配置，系统的负载分配不同的权重。不同的是，它是按照权重随机请求后端服务器，而非顺序。

    **6、最小连接数法**

       最小连接数算法比较灵活和智能，由于后端服务器的配置不尽相同，对于请求的处理有快有慢，它是根据后端服务器当前的连接情况，动态地选取其中当前积压连接数最少的一台服务器来处理当前的请求，尽可能地提高后端服务的利用效率，将负责合理地分流到每一台服务器。

* HTTP重定向负载均衡

  * 1 请求到负载均衡服务器，

    2 根据均衡算法，返回304，重定向到实际负责计算的服务器ip到浏览器，

    3 然后浏览器直接请求实际负责计算的服务器，

    4 最后实际计算的服务器响应到客户端浏览器

  * 缺点：

    1，请求经过两次服务器（负载均衡服务器，实际计算服务器），增加了响应时间。

    2，暴露了实际负载的服务器公网ip到浏览器,安全性比较低。

* DNS负载均衡

  * 1， 用户请求域名，请求到DNS服务器；

    2，DNS服务返回解析的IP地址到客户端；并不暴露到浏览器进行重定向；

    3，客户端拿到返回的负责计算的服务器IP，请求服务器；

    4，计算服务器返回响应信息；

  * 改进：

    1，不用每次都请求负载的ip,可以缓存起来，重复使用，提高性能；

    2，dns不用暴露实际计算的服务器ip（不是采用重定向的方式暴露在浏览器，而且做了二次负载均衡，内网的IP不会暴露出来）,安全性略好；

    异地多活采用的这种方式，一个ip解析到不同区域的IP，实现第一层级的负载均衡，然后基于区域ip做二级的负载均衡；

* 反向代理负载均衡nginx、apache

  * 1，客户端发起请求到负载均衡服务器，负载均衡服务器根据算法得到负载的IP；

    2，负载均衡服务器**构造请求**，请求内网负载的计算服务器；

    3， 计算服务器返回响应结果到负载均衡服务器；

    4，负载均衡服务器返回响应结果给到客户端。

* IP底层负载均衡

  * 对网络层的IP地址进行替换，不需要在http层工作，直接在操作系统内核的IP数据包中替换地址。效率比基于HTTP层的反向代理高。
    负载均衡过程：

    1，客户端请求负载均衡服务器；

    2，负载均衡服务器修改目的ip为内网机器的IP ；

    3， 内网机器计算完毕，响应的IP改为负载均衡服务器ip的内网地址；

    4，负载均衡服务器修改响应的IP为自己的外网IP ,返回结果给到客户端；

    缺点：

    请求和响应度需要经过负载均衡服务器进行ip层替换，响应数据会成为后期的瓶颈。

* 数据链路层负载均衡（一般常用的是DNS和数据链路层负载均衡。）

  * 解决响应数据体量过大效率低的问题。
    通过修改数据链路层的mac地址，ip使用的是虚拟IP，来实现负载均衡。

    负载均衡过程：

    1，客户端请求负载均衡服务器；

    2，负载均衡服务器替换mac地址为目标计算服务器，Ip为负载均衡服务器ip；

    3， 计算服务器直接响应数据到客户端；

    这种负载均衡方式吞吐量最高，大型互联网公司都是采用这种负载均衡方式。

    LVS负载均衡是结合了IP层和数据链路层的负载均衡方式。linux通过配置可以实现这两种负载均衡方式。

![image-20210327140145738](https://gitee.com/picgo-table/picgo-img/raw/master/image/image-20210327140145738.png)

### 分布式事务

* 事务ACID

  * **原子性（atomicity）**：一个事务是一个不可分割的工作单位，事务中包括的操作要么都做，要么都不做。

    **一致性（consistency）**：事务必须是使数据库从一个一致性状态变到另一个一致性状态。一致性与原子性是密切相关的。

    **隔离性（isolation）**：一个事务的执行不能被其他事务干扰。即一个事务内部的操作及使用的数据对并发的其他事务是隔离的，并发执行的各个事务之间不能互相干扰。

    **持久性（durability）**：**持久性也称永久性（permanence）**，指一个事务一旦提交，它对数据库中数据的改变就应该是永久性的。接下来的其他操作或故障不应该对其有任何影响。

* 本地消息表

![image-20210313112607685](https://gitee.com/picgo-table/picgo-img/raw/master/image/image-20210313113133566.png)

* 2PC（两阶段提交）
  * 通过消息中间件作为协调者去协调多个系统，在两个系统操作事务的时候都锁定资源但是不提交事务，等两者都准备好了，告诉消息中间件，然后再分别提交事务。
  * 问题：如果A系统事务提交成功了，但是B系统在提交的时候网络波动或者各种原因提交失败了，其实还是会失败的。

![image-20210313112629958](https://gitee.com/picgo-table/picgo-img/raw/master/image/image-20210313112607685.png)



3PC

![image-20210313112640487](https://gitee.com/picgo-table/picgo-img/raw/master/image/image-20210313112714138.png)

TCC



![image-20210313113133566](https://gitee.com/picgo-table/picgo-img/raw/master/image/image-20210313112640487.png)



RocketMQ消息事务

![image-20210313112714138](https://gitee.com/picgo-table/picgo-img/raw/master/image/image-20210313112629958.png)

* 最终一致性
  * ![image-20210326161225137](https://gitee.com/picgo-table/picgo-img/raw/master/image/image-20210326161225137.png)
  * 业务主动方本地事务提交失败，业务被动方不会收到消息的投递。
  * 只要业务主动方本地事务执行成功，那么消息服务一定会投递消息给下游的业务被动方，并最终保证业务被动方一定能成功消费该消息（消费成功或失败，即最终一定会有一个最终态）。





* 最大努力通知

  其实我觉得本地消息表也可以算最大努力，事务消息也可以算最大努力。

  就本地消息表来说会有后台任务定时去查看未完成的消息，然后去调用对应的服务，当一个消息多次调用都失败的时候可以记录下然后引入人工，或者直接舍弃。这其实算是最大努力了。

  事务消息也是一样，当半消息被commit了之后确实就是普通消息了，如果订阅者一直不消费或者消费不了则会一直重试，到最后进入死信队列。其实这也算最大努力。

  所以**最大努力通知其实只是表明了一种柔性事务的思想**：我已经尽力我最大的努力想达成事务的最终一致了。

  适用于对时间不敏感的业务，例如短信通知。

  

### Sentinel

* 限流
  * Sentinel Starter 默认为所有的 HTTP 服务提供了限流埋点，我们也可以通过使用@SentinelResource来自定义一些限流行为。

  * 可以根据@SentinelResource注解中定义的value（资源名称）来进行限流操作，但是需要指定限流处理逻辑。

  * 在Sentinel控制台配置流控规则，根据@SentinelResource注解的value值，通过资源名称来限流

  * 我们还可以通过访问的URL来限流，会返回默认的限流处理信息。

  * 自定义限流处理逻辑：

    ```java
    	@GetMapping("/blockHandler")
        @SentinelResource(value = "blockHandler", blockHandler = "handleException",blockHandlerClass = CustomBlockHandler.class)
    ```

* 熔断

  * Sentinel 支持对服务间调用进行保护，对故障应用进行熔断操作

  * 1、可以使用@SentinelRestTemplate来包装下RestTemplate实例：

    ```java
    @Configuration
    public class RibbonConfig {
        @Bean
        @SentinelRestTemplate
        public RestTemplate restTemplate(){
            return new RestTemplate();
        }
    }
    @RequestMapping("/fallback/{id}")
    @SentinelResource(value = "fallback",fallback = "handleFallback")
    public CommonResult fallback(@PathVariable Long id) {
    	return restTemplate.getForObject(userServiceUrl + "/user/{1}", CommonResult.class, id);
    }
    public CommonResult handleFallback(Long id) {
        User defaultUser = new User(-1L, "defaultUser", "123456");
        return new CommonResult<>(defaultUser,"服务降级返回",200);
    }
    ```

  * 2、也可以配合Feign实现熔断

    * ```
      feign:
        sentinel:
          enabled: true #打开sentinel对feign的支持
      ```

    * ```
      @FeignClient(value = "nacos-user-service",fallback = UserFallbackService.class)
      public interface UserService {
          @PostMapping("/user/create")
          CommonResult create(@RequestBody User user);
      }
      ```

* 使用nacos存储规则

  * 默认情况下，当我们在Sentinel控制台中配置规则时，控制台推送规则方式是通过API将规则推送至客户端并直接**更新到内存**中。一旦我们重启应用，规则将消失。下面我们介绍下如何将配置规则进行持久化，以存储到Nacos为例。

  * 首先我们直接在配置中心创建规则，配置中心将规则推送到客户端；

  * Sentinel控制台也从配置中心去获取配置信息。

    ```
    [
        {
            "resource": "/rateLimit/byUrl",
            "limitApp": "default",
            "grade": 1,
            "count": 1,
            "strategy": 0,
            "controlBehavior": 0,
            "clusterMode": false
        }
    ]
    ```

    

  

  

### Gateway网关

* Gateway旨在提供一种简单而有效的方式来对API进行路由，以及提供一些强大的过滤器功能， 例如：熔断、限流、重试等。
* 特性
  * 基于Spring Framework 5, Project Reactor 和 Spring Boot 2.0 进行构建；
  * 动态路由：能够匹配任何请求属性；
  * 可以对路由指定 **Predicate（断言）和 Filter（过滤器）**；
  * 集成 Hystrix 的**断路器**功能；
  * 集成 Spring Cloud **服务发现**功能；
  * 易于编写的 Predicate（断言）和 Filter（过滤器）；
  * 请求**限流**功能；
  * 支持路径重写。
* 概念
  * **Route**（路由）：路由是构建网关的基本模块，它由ID，目标URI，一系列的断言和过滤器组成，如果断言为true则匹配该路由；
  * **Predicate**（断言）：指的是Java 8 的 Function Predicate。 输入类型是Spring框架中的ServerWebExchange。 这使开发人员可以匹配HTTP请求中的所有内容，例如请求头或请求参数。如果请求与断言相匹配，则进行路由；
  * **Filter**（过滤器）：指的是Spring框架中GatewayFilter的实例，使用**过滤器**，可以在请求**被路由前后对请求进行修改。**

* 配置

  * Gateway 提供了两种不同的方式用于配置路由，一种是通过yml文件来配置，另一种是通过Java Bean来配置

  * ```
    spring:
      cloud:
        gateway:
          routes:
            - id: path_route #路由的ID
              uri: ${service-url.user-service}/user/{id} #匹配后路由地址
              predicates: # 断言，路径相匹配的进行路由
                - Path=/user/{id}
    ```

  * Bean配置

    ```java
    @Configuration
    public class GatewayConfig {
        @Bean
        public RouteLocator customRouteLocator(RouteLocatorBuilder builder) {
            return builder.routes()
                    .route("path_route2", r -> r.path("/user/getByUsername")
                            .uri("http://localhost:8201/user/getByUsername"))
                    .build();
        }
    }
    ```

* 使用

  * Predicate

    * 带有指定cookie的请求会匹配该路由

      ```
      spring:
        cloud:
          gateway:
            routes:
              - id: cookie_route
                uri: ${service-url.user-service}
                predicates:
                  - Cookie=username,macro
      ```

    * 带有指定请求头 X-Request-Id 的请求会匹配该路由。`\- Header=X-Request-Id, \d+`

    * 带有指定Host的请求会匹配该路由。`\- Host=**.macrozheng.com`

    * 发送指定方法的请求会匹配该路由。`- Method=GET`

    * 带指定查询参数的请求可以匹配该路由。`\- Query=username`

    * 发送指定路径的请求会匹配该路由。`\- Path=/user/{id}`

    * 使用权重来路由相应请求，以下表示有80%的请求会被路由到localhost:8201，20%会被路由到localhost:8202。

      ```yaml
      spring:
        cloud:
          gateway:
            routes:
            - id: weight_high
              uri: http://localhost:8201
              predicates:
              - Weight=group1, 8
            - id: weight_low
              uri: http://localhost:8202
              predicates:
              - Weight=group1, 2
      ```

* Boute Filter

  * 路由过滤器可用于**修改进入的HTTP请求和返回的HTTP响应**，路由过滤器只能指定路由进行使用。Spring Cloud Gateway 内置了多种路由过滤器，他们都由**GatewayFilter的工厂类**来产生

  * 给请求添加参数的过滤器。

    ```
    spring:
      cloud:
        gateway:
          routes:
            - id: add_request_parameter_route
              uri: http://localhost:8201
              filters:
                - AddRequestParameter=username, macro
              predicates:
                - Method=GET
    ```

  * 对指定数量的路径前缀进行去除的过滤器，把以`/user-service/`开头的请求的路径去除两位。`\- StripPrefix=2`

  * 与StripPrefix过滤器恰好相反，会对原有路径进行增加操作的过滤器。`\- PrefixPath=/user`

  * Hystrix 过滤器：并在yml添加配置：当路由出错时会转发到服务降级处理的控制器上：

    ```
    spring:
      cloud:
        gateway:
          routes:
            - id: hystrix_route
              uri: http://localhost:8201
              predicates:
                - Method=GET
              filters:
                - name: Hystrix
                  args:
                    name: fallbackcmd
                    fallbackUri: forward:/fallback
    
    ```

    ```
    @RestController
    public class FallbackController {
        @GetMapping("/fallback")
        public Object fallback() {
            Map<String,Object> result = new HashMap<>();
            result.put("data",null);
            result.put("message","Get request fallback!");
            result.put("code",500);
            return result;
        }
    }
    ```

  * RequestRateLimiter 过滤器可以用于限流，使用RateLimiter实现来确定是否允许当前请求继续进行，如果请求太大默认会返回HTTP 429-太多请求状态。

    * 添加限流策略的配置类，这里有两种策略一种是根据请求参数中的username进行限流，另一种是根据访问IP进行限流；

      ```
      @Configuration
      public class RedisRateLimiterConfig {
          @Bean
          KeyResolver userKeyResolver() {
              return exchange -> Mono.just(exchange.getRequest().getQueryParams().getFirst("username"));
          }
          @Bean
          public KeyResolver ipKeyResolver() {
              return exchange -> Mono.just(exchange.getRequest().getRemoteAddress().getHostName());
          }
      }
      ```

    * 我们使用Redis来进行限流，所以需要添加Redis和RequestRateLimiter的配置，这里对所有的GET请求都进行了按IP来限流的操作；

      ```
      spring:
        cloud:
          gateway:
            routes:
              - id: requestratelimiter_route
                uri: http://localhost:8201
                filters:
                  - name: RequestRateLimiter
                    args:
                      redis-rate-limiter.replenishRate: 1 #每秒允许处理的请求数量
                      redis-rate-limiter.burstCapacity: 2 #每秒最大处理的请求数量
                      key-resolver: "#{@ipKeyResolver}" #限流策略，对应策略的Bean
                predicates:
                  - Method=GET
      logging:
        level:
          org.springframework.cloud.gateway: debug
      ```

  * Retry过滤器：对路由请求进行重试的过滤器，可以根据路由请求返回的HTTP状态码来确定是否进行重试。

    ```
    spring:
      cloud:
        gateway:
          routes:
          - id: retry_route
            uri: http://localhost:8201
            predicates:
            - Method=GET
            filters:
            - name: Retry
              args:
                retries: 1 #需要进行重试的次数
                statuses: BAD_GATEWAY #返回哪个状态码需要进行重试，返回状态码为5XX进行重试
                backoff:
                  firstBackoff: 10ms
                  maxBackoff: 50ms
                  factor: 2
                  basedOnPreviousValue: false
    
    ```

* 结合注册中心创建动态路由，在结合注册中心使用过滤器的时候，我们需要注意的是uri的协议为`lb`，这样才能启用Gateway的负载均衡功能。

  ```
  spring:
    application:
      name: api-gateway
    cloud:
      gateway:
        routes:
          - id: prefixpath_route
            uri: lb://user-service #此处需要使用lb协议
            predicates:
              - Method=GET
            filters:
              - PrefixPath=/user
        discovery:
          locator:
            enabled: true
            lower-case-service-id: true #使用小写服务名，默认是大写
  ```

* 全局跨域问题CORS

  ```
  /**
   * 全局跨域配置
   * 注意：前端从网关进行调用时不需要配置
   * Created by macro on 2019/7/27.
   */
  //@Configuration
  public class GlobalCorsConfig {
      /**
       * 允许跨域调用的过滤器
       */
      @Bean
      public CorsFilter corsFilter() {
          CorsConfiguration config = new CorsConfiguration();
          //允许所有域名进行跨域调用
          config.addAllowedOrigin("*");
          //允许跨越发送cookie
          config.setAllowCredentials(true);
          //放行全部原始头信息
          config.addAllowedHeader("*");
          //允许所有请求方法跨域调用
          config.addAllowedMethod("*");
          UrlBasedCorsConfigurationSource source = new UrlBasedCorsConfigurationSource();
          source.registerCorsConfiguration("/**", config);
          return new CorsFilter(source);
      }
  }
  
  ```

### 权限验证

* JWT
  * 内容：
    * 
  * 优点
    * 无需再服务端存储用户数据，减轻服务端压力
    * 轻量级，json风格，比较简单
    * 跨语言
  * 缺点
    * token一旦签发，无法修改
      - 无法更新token有效期，用户登录状态刷新难以实现
      - 无法销毁一个token，服务端不能对用户状态进行绝对控制

* 如果token有效期过短，如何保持会话

  * token要到期时，在重新生成一份token

* 如何销毁jwt

  * 生成token时，有效期设置短一些

    可以和redis结合使用，退出时销毁redis的token。判断redis的token即可

    还可以添加黑名单功能，对其进行拦截

* 如何防止cookie被篡改

  * 可以设置cookie的状态为httponly（通过js脚本将无法读取到cookie信息，这样能有效的防止XSS攻击，窃取cookie内容，这样就增加了cookie的安全性）
  * 使用HTTPS

  * 可以在请求中添加防盗链

    * 判断http请求头**Referer域**中的记录**来源的值**，如果和当前访问的域名不一致的情况下，说明该图片可能被其他服务器盗用。
      使用**过滤器拦截请求**，判断请求头中的域名与需要限制的域名访问是否一致，如果不一致的情况，说明可能被盗用。

      使用过滤器判断请求头Referer记录请求来源

  * 可以把token存放在请求头中或者local storage中，由于无状态的token过长，很容易达到4kb

  * 由于容易被篡改，payload中不要放用户重要信息，如不要放密码

* 如何防止token被篡改

  * jwt使用了header和payload参数来校验是否被篡改，header存放算法类型和类型是jwt方式的参数，payload是存放用户自定义的参数，还有签名结合来确认token是否被篡改

* 怎么做权限控制的

  * 我们有一套权限控制服务，保存用户的角色和路径信息、当用户发起请求的时候，通过网关的的全局pre过滤器拦截所有请求，获取请求信息，解析jwt参数，根据参数获取用户，根据用户明去查询数据库的用户是否存在，以及当前用户有无访问此地址的权限，没有即拦截

* 如何解决token注销问题

  * jwt的缺陷是token生成后无法修改，因此无法让token失效。只能采用其它方案来弥补，基本思路如下：
    方案一：
    1）适当减短token有效期，让token尽快失效
    2）删除客户端cookie
    3）服务端对失效token进行标记，形成黑名单，虽然有违无状态特性，但是因为token有效期短，因此标记 时间也比较短。服务器压力会比较小
    方案二：
    1）用户登录后，生成JWT
    2）把JWT的id存入redis，只有redis中有id的JWT，才是有效的JWT
    3）退出登录时，把ID从Redis删除即可

* token有效期短，怎么解决token失效后的续签问题？

  * 在验证用户登录状态的代码中，添加一段逻辑：判断cookie即将到期时，重新生成一个token。比如token有效期为30分钟，当用户请求我们时，我们可以判断如果用户的token有效期还剩下10分钟，那么就重新生成token。因此用户只要在操作我们的网站，就会续签token

* 如何解决异地登录问题？

  * JWT设计为了实现无状态的登录，因此token无法修改，难以实现异地登录的判断，或者强制让登录token失效。
    因此如果有类似需求， 就不应选择JWT作为登录方案，而是使用传统session登录方案。
    但是，如果一定要用JWT实现类似要过，就需要在Redis中记录登录用户的JWT的token信息，这样就成了有状态的登录，还不如一开始就选择Session方案。

* 如何解决cookie被盗用问题？

  * cookie被盗用的可能性主要包括下面几种：

    XSS攻击：这个可以再前端页面渲染时对 数据做安全处理即可，而且我们的cookie使用了Httponly为true，可以防止JS脚本的攻击。
    CSRF攻击：
    利用Referer头，防盗链
    请求头中加随机码
    抓包，获取用户cookie：我们采用了HTTPS协议通信，无法获取请求的任何数据
    请求重放攻击：对于普通用户的请求没有对请求重放做防御，而是对部分业务做好了幂等处理。运行管理系统中会对token添加随机码，认证token一次有效，来预防请求重放攻击。
    用户电脑中毒：这个无法防范。

* 用户的cookie被禁用怎么办？

  * cookie一般情况下，是不会被禁用，因为普通人根本不知道是什么是cookie，一般不用管，为了友好，我们可以给用户一个提示：你的cookie已经被禁用了，请启用cookie。
    把jwt作为响应头返回，浏览器中JS把token写到本地存储（sessionStorage），要求前端每次发ajax，都必须自己携带token。而且有被xss攻击的风险

* 服务端微服务地址暴露，用户绕过网关直接访问微服务，怎么办

  * 首先，我们的微服务隐藏在网关的后面，而且整个服务被Nginx反向代理，用户只能看到nginx的地址，微服务暴露的可能性很低。
    然后，即便真的暴露了，我们的微服务都做了严格的服务间鉴权处理，任何对微服务的访问都会被验证是否有授权，如果没有则会被拦截。具体实现：
    会有一张表记录每个微服务的id，和密钥信息
    服务启动时，需要去授权中心，认证身份，携带id和secret
    授权中心认证通过，会颁发一个JWT给微服务
    微服务访问其它服务时，需要携带JWT
    被访问的服务，需要验证JWT，如果没有携带，或token时伪造的拦截请求即可

* XSS
  * XSS全称Cross SiteScript，跨站脚本攻击 ，XSS属于被动式且用于客户端的攻击方式，所以容易被忽略其危害性。其原理是攻击者向有XSS漏洞的网站中输入(传入)恶意的HTML代码，当其它用户浏览该网站时，这段HTML代码会自动执行，从而达到攻击的目的。如，盗取用户Cookie、破坏页面结构、重定向到其它网站等。

  * XSS有三类：反射型XSS(非持久型)、存储型XSS(持久型)和DOM XSS。

  * 防御XSS攻击

    * 最普遍的做法是**转义输入输出的内容**，对于引号，尖括号，斜杠进行转义

    * XSS防御的总体思路是：**对输入(和URL参数)进行过滤，对输出进行编码**。

      也就是对提交的所有内容进行过滤，对url中的参数进行过滤，过滤掉会导致脚本执行的相关内容；然后对动态输出到页面的内容进行html编码，使脚本无法在浏览器中执行。**虽然对输入过滤可以被绕过，但是也还是会拦截很大一部分的XSS攻击**。

* OAuth2
  * 用于REST/APIs的**代理授权框架**(delegated authorization framework)
    **基于令牌Token**的授权，在无需暴露用户密码的情况下，使应用能获取对用户数据的有限访问权限
    
  * OAuth 简单理解就是一种**授权机制**，它是在客户端和资源所有者之间的**授权层**，用来**分离两种不同的角色**。在授权服务器AS同意并向客户端颁发令牌后，客户端携带令牌可以通过资源服务器RS访问到资源拥有者的资源。

  * 例子：在家肝文章饿了定了一个外卖，外卖小哥30秒火速到达了我家楼下，奈何有门禁进不来，可以输入密码进入，但出于安全的考虑我并不想告诉他密码。此时外卖小哥看到门禁有一个高级按钮“`一键获取授权`”，只要我这边同意，他会获取到一个有效期 2小时的令牌（`token`）正常出入。`token` 拥有权限范围，有时效性的，到期自动失效，而且无效修改。

  * ![image-20210404091829389](https://gitee.com/picgo-table/picgo-img/raw/master/image/image-20210404091829389.png)

  * 客户应用:通常是一个Web或者无线应用，它需要访问用户的受保护资源
    资源服务器:是一个web站点或者web service API，用户的受保护数据保存于此
    授权服务器: 在客户应用成功认证并获得授权之后，向客户应用**颁发访问令牌Access Token**
    资源拥有者:资源的拥有人，想要分享某些资源给第三方应用
    客户凭证: 客户的**clientId 和密码**用于认证客户
    令牌: 授权服务器在接收到客户请求后，颁发的访问令牌
    作用域: 客户请求访问令牌时，由资源拥有者额外指定的细分权限(permission)

  * JWT

    * JWT全称是JSON Web Token是一个开放标准(RFC 7519)，目前最流行的跨域身份验证解决方案。
      它定义了一种经过加密的格式，放在json对象在请求中传递，用于验证请求是否被允许访问。

    * 服务器经过认证以后，会生成加密串返回前台

    * JSON Web Token由三部分组成，它们之间用.连接。Header 头部、Payload 负载、Signature 签名

    * **Header**

      * Header 部分用Base64URL解密后是一个JSON对象，主要描述了签名的算法和令牌类型。

      * ```json
            {
              "alg": "HS256",
              "typ": "JWT"
            }
        alg属性表示签名使用的算法，默认为HMAC SHA256（写为HS256），typ属性表示令牌的类型，JWT令牌统一写为JWT。
        ```

    * **Payload** 负载

      * 同样也是一个JSON对象，它包含Claim。JWT的信息默认是不加密的，Payload传递的不要有秘密信息。

      * Claim中存的就是这些字段，有三种类型：

        > - Registered claims 预定义的声明
        > - Public claims 公开声明
        > - Private claims 私有声明

    * **Signature**

      * Signature 部分是对**前两部分的签名，用来防止数据篡改。**

        服务端指定密钥（secret），使用Header指定的签名算法，用转码后的JWT串产生签名。

    * JWT使用：客户端收到服务器返回的 JWT，需要自己存储在 Cookie 或者 localStorage中。

      此后的每一次请求都必须带上这个 JWT，放在 cookie 中是无法跨域的，所以我们需要在 HTTP 请求的头信息或者参数中带上。

    * JWT与Session差异

      * 首先要明确，http协议是无状态的，每次请求对服务端而言，是不清楚上一次请求的认证。

        session 的做法是将已经认证过的用户信息存储在服务器，用户下次请求带上 Session ID，服务器依此判断用户是否认证过。
         因此也带来了一些问题：

        > - 开销： 用户信息保存在内存中，认证的用户越多，内存开销越大。
        > - 扩展性：不方便扩展，虽然可以将session存储在redis中，但是对程序的稳定性又带来不确定
        > - CORS：跨资源共享问题，调用从另一个域名下获取资源时，会遇到禁止请求。

        与之相反的是 JWT 这种令牌认证方式，基于Token的身份认证是无状态的，服务器或者Session中不会存储任何用户信息，方便无状态的服务扩展，尤其适合做单点登录和手机端的鉴权。
         但JWT也有不足，令牌一旦发出，是无法作废的，到期之前一直有效。

  * OAuth2.0参数：

    * response_type：code 表示要求返回授权码，token 表示直接返回令牌
      client_id：客户端身份标识
      client_secret：客户端密钥
      redirect_uri：重定向地址
      scope：表示授权的范围，read只读权限，all读写权限
      grant_type：表示授权的方式，AUTHORIZATION_CODE（授权码）、password（密码）、client_credentials（凭证式）、refresh_token 更新令牌
      state：应用程序传递的一个随机数，用来防止CSRF攻击

  * 授权方式（获取令牌`token`）：授权码、隐藏式、密码是、客户端凭证。

    * 不管我们使用哪一种授权方式，在三方应用申请令牌之前，都必须在系统中去申请身份唯一标识：客户端 ID（`client ID`）和 客户端密钥（`client secret`）。这样做可以保证 `token` 不被恶意使用。

    * 授权码：

      * 最为复杂，但也是安全系数最高的，适用于兼具前后端的`Web`项目
      * ![image-20210404164425175](https://gitee.com/picgo-table/picgo-img/raw/master/image/image-20210404164425175.png)

    * 隐藏式：适用于前后端分离项目

      * 令牌的申请与存储都需要在前端完成，跳过了授权码这一步。

        前端应用**直接获取 token**，response_type 设置为 token，要求直接返回令牌，跳过授权码，WX授权通过后重定向到指定 redirect_uri 。

    * 密码式：（不安全）

      * 密码模式比较好理解，用户在掘金直接输入自己的`WX`用户名和密码，掘金拿着信息直接去`WX`申请令牌，请求响应的 `JSON`结果中返回 `token`。`grant_type` 为 `password` 表示密码式授权。

    * 凭证式

      * 凭证式和密码式很相似，主要适用于那些没有前端的命令行应用，可以用最简单的方式获取令牌，在请求响应的 JSON 结果中返回 token。

        grant_type 为 client_credentials 表示凭证式授权，client_id 和 client_secret 用来识别身份。

  * 令牌使用

    * 每个到达WX的请求都必须带上 token，将 token 放在 http 请求头部的一个**Authorization**字段里。

  * 令牌过期：

    一般在颁发令牌时会**一次发两个令牌**，一个令牌用来**请求API**，另一个负责**更新令牌 refresh_token**。grant_type 为 refresh_token 请求为更新令牌，参数 refresh_token 是用于更新令牌的令牌

  





 





### Dubbo

![image-20210404125720269](https://gitee.com/picgo-table/picgo-img/raw/master/image/image-20210404125720269.png)

* 工作原理
  * 服务启动的时候，provider和consumer根据配置信息，连接到注册中心register，分别向注册中心注册和订阅服务
  * register根据服务订阅关系，返回provider信息到consumer，同时consumer会把provider信息缓存到本地。如果信息有变更，consumer会收到来自register的推送
  * consumer生成代理对象，同时根据负载均衡策略，选择一台provider，同时定时向monitor记录接口的调用次数和时间信息
  * 拿到代理对象之后，consumer通过代理对象发起接口调用
  * provider收到请求后对数据进行反序列化，然后通过代理调用具体的接口实现
* 负载均衡策略
  * 加权随机：假设我们有一组服务器 servers = [A, B, C]，他们对应的权重为 weights = [5, 3, 2]，权重总和为10。现在把这些权重值平铺在一维坐标值上，[0, 5) 区间属于服务器 A，[5, 8) 区间属于服务器 B，[8, 10) 区间属于服务器 C。接下来通过随机数生成器生成一个范围在 [0, 10) 之间的随机数，然后计算这个随机数会落到哪个区间上就可以了。
  * 最小活跃数：每个服务提供者对应一个活跃数 active，初始情况下，所有服务提供者活跃数均为0。每收到一个请求，活跃数加1，完成请求后则将活跃数减1。在服务运行一段时间后，性能好的服务提供者处理请求的速度更快，因此活跃数下降的也越快，此时这样的服务提供者能够优先获取到新的服务请求。
  * 一致性hash：通过hash算法，把provider的invoke和随机节点生成hash，并将这个 hash 投射到 [0, 2^32 - 1] 的圆环上，查询的时候根据key进行md5然后进行hash，得到第一个节点的值大于等于当前hash的invoker。
  * 加权轮询：比如服务器 A、B、C 权重比为 5:2:1，那么在8次请求中，服务器 A 将收到其中的5次请求，服务器 B 会收到其中的2次请求，服务器 C 则收到其中的1次请求。
* 集群容错
  * Failover Cluster失败自动切换：dubbo的默认容错方案，当调用失败时自动切换到其他可用的节点，具体的重试次数和间隔时间可用通过引用服务的时候配置，默认重试次数为1也就是只调用一次。
  * Failback Cluster快速失败：在调用失败，记录日志和调用信息，然后返回空结果给consumer，并且通过定时任务每隔5秒对失败的调用进行重试
  * Failfast Cluster失败自动恢复：只会调用一次，失败后立刻抛出异常
  * Failsafe Cluster失败安全：调用出现异常，记录日志不抛出，返回空结果
  * Forking Cluster并行调用多个服务提供者：通过线程池创建多个线程，并发调用多个provider，结果保存到阻塞队列，只要有一个provider成功返回了结果，就会立刻返回结果
  * Broadcast Cluster广播模式：逐个调用每个provider，如果其中一台报错，在循环调用结束后，抛出异常。

* RPC 对比的是本地过程调用，是用来作为分布式系统之间的通信，它可以用 HTTP 来传输，也可以基于 TCP 自定义协议传输。

![image-20210317195048251](https://gitee.com/picgo-table/picgo-img/raw/master/image/image-20210317195048251.png)

* 服务消费者 **Consumer 启动向注册中心订阅**自己所需的服务。然后注册中心将提供者元信息通知给 Consumer， 之后 Consumer 因为已经从注册中心获取提供者的地址，因此可以**通过负载均衡选择一个 Provider 直接调用** 。之后服务提供方元数据变更的话**注册中心会把变更推送给服务消费者**。服务提供者和消费者都会在内存中记录着调用的次数和时间，然后**定时的发送统计数据到监控中心**。

* 大致三层分别为 Business（业务层）、RPC 层、Remoting，并且还分为 API 层和 SPI 层。而分 API 层和 SPI 层这是 Dubbo 成功的一点，**采用微内核设计+SPI扩展**，使得有特殊需求的接入方可以自定义扩展，做定制的二次开发。

*  SPI（Service Provider Interface），是 JDK 内置的一个服务发现机制，**它使得接口和具体实现完全解耦**。我们只声明接口，具体的实现类在配置中选择。具体的就是你定义了一个接口，然后在`META-INF/services`目录下**放置一个与接口同名的文本文件**，文件的内容为**接口的实现类**，多个实现类用换行符分隔。这样就通过配置来决定具体用哪个实现

* 服务暴露过程：

  * 从对象构建转换的角度：

    * 服务的暴露起始于 Spring IOC 容器刷新完毕之后，会根据配置参数组装成 URL， 然后根据 URL 的参数来进行本地或者远程调用。

      会通过 `proxyFactory.getInvoker`，利用 javassist 来进行动态代理，封装实现类为 Invoker，然后再通过 URL 参数选择对应的协议来进行 protocol.export，默认是 Dubbo 协议。

      在第一次暴露的时候会调用 createServer 来创建 Server，默认是 NettyServer。

      然后将 export 得到的 exporter 存入一个 Map 中，供之后的远程调用查找，然后会向注册中心注册提供者的信息。

    * ![image-20210318091616889](https://gitee.com/picgo-table/picgo-img/raw/master/image/image-20210318091616889.png)

  * 从代码流程：

    * 第一步是检测配置，如果有些配置空的话会默认创建，并且组装成 URL 。

      第二步是暴露服务，包括暴露到本地的服务和远程的服务。

      第三步是注册服务至注册中心。

    * ![image-20210318091629562](https://gitee.com/picgo-table/picgo-img/raw/master/image/image-20210318091629562.png)

* 服务引入过程

  * 服务的引入时机有两种，第一种是饿汉式，第二种是懒汉式。

  * 饿汉式就是加载完毕就会引入，懒汉式是只有当这个服务被注入到其他类中时启动引入流程，默认是懒汉式。

    会先根据配置参数组装成 URL ，一般而言我们都会配置的注册中心，所以会构建 RegistryDirectory 向注册中心注册消费者的信息，并且订阅提供者、配置、路由等节点。

    得知提供者的信息之后会进入 Dubbo 协议的引入，会创建 Invoker ，期间会包含 NettyClient，来进行远程通信，最后通过 Cluster 来包装 Invoker，默认是 FailoverCluster，最终返回代理类。

* 服务调用过程

  * ![image-20210318091921494](https://gitee.com/picgo-table/picgo-img/raw/master/image/image-20210318091921494.png)

  * 首先消费者启动会向注册中心拉取服务提供者的元信息，然后调用流程也是从 Proxy 开始，毕竟都需要代理才能无感知。

    Proxy 持有一个 Invoker 对象，调用 invoke 之后需要通过 Cluster 先从 Directory 获取所有可调用的远程服务的 Invoker 列表，如果配置了某些路由规则，比如某个接口只能调用某个节点的那就再过滤一遍 Invoker 列表。

    剩下的 Invoker 再通过 LoadBalance 做负载均衡选取一个。然后再经过 Filter 做一些统计什么的，再通过 Client 做数据传输，比如用 Netty 来传输。

    传输需要经过 Codec 接口做协议构造，再序列化。最终发往对应的服务提供者。

    服务提供者接收到之后也会进行 Codec 协议处理，然后反序列化后将请求扔到线程池处理。某个线程会根据请求找到对应的 Exporter ，而找到 Exporter 其实就是找到了 Invoker，但是还会有一层层 Filter，经过一层层过滤链之后最终调用实现类然后原路返回结果。

* 集群容错负载均衡

  * 首先在服务引入的时候，将多个远程调用都塞入 Directory 中，然后通过 Cluster 来封装这个目录，封装的同时提供各种容错功能，比如 FailOver、FailFast 等等，最终暴露给消费者的就是一个 invoker。

    然后消费者调用的时候会从目录里面得到 invoker 列表，当然会经过路由的过滤，得到这些 invokers 之后再由 loadBalance 来进行负载均衡选择一个 invoker，最终发起调用。这种过程其实是在 Cluster 的内部发起的，所以能在发起调用出错的情况下，用上容错的各种措施。

* 设计RPC

  * 首先需要实现高性能的网络传输，可以采用 Netty 来实现，不用自己重复造轮子，然后需要自定义协议，毕竟远程交互都需要遵循一定的协议，然后还需要定义好序列化协议，网络的传输毕竟都是二进制流传输的。

    然后可以搞一套描述服务的语言，即 IDL（Interface description language），让所有的服务都用 IDL 定义，再由框架转换为特定编程语言的接口，这样就能跨语言了。

    此时最近基本的功能已经有了，但是只是最基础的，工业级的话首先得易用，所以框架需要把上述的细节对使用者进行屏蔽，让他们感觉不到本地调用和远程调用的区别，所以需要代理实现。

    然后还需要实现集群功能，因此的要服务发现、注册等功能，所以需要注册中心，当然细节还是需要屏蔽的。

    最后还需要一个完善的监控机制，埋点上报调用情况等等，便于运维。

### Zookeeper

* 统一配置管理、统一命名服务、分布式锁、集群管理。

* ZooKeeper的数据结构，跟Unix文件系统非常类似，可以看做是一颗**树**，每个节点叫做**ZNode**。每一个节点可以通过**路径**来标识![image-20210318100309178](https://gitee.com/picgo-table/picgo-img/raw/master/image/image-20210318100309178.png)

* Znode分为：

  * **短暂/临时(Ephemeral)**：当客户端和服务端断开连接后，所创建的Znode(节点)**会自动删除**
  * **持久(Persistent)**：当客户端和服务端断开连接后，所创建的Znode(节点)**不会删除**

* ZooKeeper还配合了**监听器**才能够做那么多功能，监听场景有：

  * 监听Znode节点的**数据变化**
  * 监听子节点的**增减变化**

* 统一配置管理：子节点监听父节点的配置改变，当父节点Znode节点变更，就及时响应并，不需要重启系统

* 统一命名服务：跟域名一样，通过域名在zookeeper中获取到对应节点的IP，再去获取资源

* 分布式锁：访问的时候会创建**带顺序号的临时/短暂**节点

  * 拿到父节点下的所有子节点(id_000000,id_000001,id_000002)，子节点**判断自己创建的是不是最小的那个节点**

    - 如果是，则拿到锁。

    - - 释放锁：执行完操作后，把创建的当前子节点给删掉

    - 如果不是，则监听比自己要小1的节点变化

  * 详细：zk通过临时节点，解决掉了**死锁**的问题，一旦客户端获取到锁之后突然挂掉（Session连接断开），那么这个临时节点就会自动删除掉，其他客户端自动获取锁。

    zk通过节点排队监听的机制，也实现了**阻塞**的原理，其实就是个递归在那无限等待最小节点释放的过程。

    实现**可重入**了，带上线程信息就可以了，或者机器信息这样的唯一标识，获取的时候判断一下。

    zk的集群也是**高可用**的，只要半数以上的节点可以使用，就可以对外提供服务了。

* 集群状态

  * ![image-20210318101621908](https://gitee.com/picgo-table/picgo-img/raw/master/image/image-20210318101621908.png)

  * 只要系统挂了，那`/groupMember/A`这个节点就会删除，通过**监听**`groupMember`下的子节点，系统B和C就能够感知到系统A已经挂了。(新增也是同理)

  * 除了能够感知节点的上下线变化，ZooKeeper还可以实现**动态选举Master**的功能。(如果集群是主从架构模式下)

    原理也很简单，如果想要实现动态选举Master的功能，Znode节点的类型是带**顺序号的临时节点**(`EPHEMERAL_SEQUENTIAL`)就好了。

    - Zookeeper会每次选举最小编号的作为Master，如果Master挂了，自然对应的Znode节点就会删除。然后让**新的最小编号作为Master**，这样就可以实现动态选举的功能了。

* SSO单点登录

  * 单系统登录功能主要是用Session保存用户信息来实现的，但我们清楚的是：多系统即可能有多个Tomcat，而Session是依赖当前系统的Tomcat，所以系统A的Session和系统B的Session是**不共享**的。
  * 解决方案：
    * Tomcat集群Session全局复制（集群内每个tomcat的session完全同步）【会影响集群的性能，不建议】
    * 根据请求的IP进行**Hash映射**到对应的机器上（这就相当于请求的IP一直会访问同一个服务器）【如果服务器宕机了，会丢失了一大部分Session的数据，不建议】
    * 把Session数据放在Redis中（使用Redis模拟Session）【**建议**】
      * SSO系统生成一个token，并将用户信息存到Redis中，并设置过期时间
      * 其他系统请求SSO系统进行登录，得到SSO返回的token，写到Cookie中
      * 每次请求时，Cookie都会带上，拦截器得到token，判断是否已经登录
  * cookie跨域问题
    * **由于域名不同**，用户向系统A登录后，系统A返回给浏览器的Cookie，用户再请求系统B的时候不会将系统A的Cookie带过去。
    * 解决方案：
      * 服务端将Cookie写到客户端后，客户端对Cookie进行解析，将Token解析出来，此后请求都把这个Token带上就行了
      * 多个域名共享Cookie，在写到客户端的时候设置Cookie的domain。
      * 将Token保存在SessionStroage中（不依赖Cookie就没有跨域的问题了）
  * CAS（Central Authentication Service）
    * 首先，用户想要访问系统A`www.java3y.com`受限的资源(比如说购物车功能，购物车功能需要登录后才能访问)，系统A`www.java3y.com`发现用户并没有登录，于是**重定向到sso认证中心，并将自己的地址作为参数**。请求的地址如下：
      - `www.sso.com?service=www.java3y.com`
    * sso认证中心发现用户未登录，将用户引导至登录页面，用户进行输入用户名和密码进行登录，用户与认证中心建立**全局会话（生成一份Token，写到Cookie中，保存在浏览器上）**
    * 随后，认证中心**重定向回系统A**，并把Token携带过去给系统A，重定向的地址如下：
      - `www.java3y.com?token=xxxxxxx`
    * 接着，系统A去sso认证中心验证这个Token是否正确，如果正确，则系统A和用户建立局部会话（**创建Session**）。到此，系统A和用户已经是登录状态了。
    * 此时，用户想要访问系统B`www.java4y.com`受限的资源(比如说订单功能，订单功能需要登录后才能访问)，系统B`www.java4y.com`发现用户并没有登录，于是**重定向到sso认证中心，并将自己的地址作为参数**。请求的地址如下：
      - `www.sso.com?service=www.java4y.com`
    * 注意，因为之前用户与认证中心`www.sso.com`已经建立了全局会话（当时已经把Cookie保存到浏览器上了），所以这次系统B**重定向**到认证中心`www.sso.com`是可以带上Cookie的。
    * 认证中心**根据带过来的Cookie**发现已经与用户建立了全局会话了，认证中心**重定向回系统B**，并把Token携带过去给系统B，重定向的地址如下：
      - `www.java4y.com?token=xxxxxxx`
    * 接着，系统B去sso认证中心验证这个Token是否正确，如果正确，则系统B和用户建立局部会话（**创建Session**）。到此，系统B和用户已经是登录状态了。
    * 看到这里，其实SSO认证中心就类似一个**中转站**。

* ZAB协议

  * 为ZooKeeper协设计的崩溃恢复原子广播协议，它保证zookeeper集群数据的一致性和命令的全局有序性。

  * **zookeeper集群角色**:

    * Leader：同一时间集群总只允许有一个Leader，提供对客户端的读写功能，负责将数据同步至各个节点；
    * Follower：提供对客户端读功能，写请求则转发给Leader处理，当Leader崩溃失联之后参与Leader选举；
    * Observer：与Follower不同的是但不参与Leader选举。

  * **zookeeper服务状态**

    * LOOKING：当节点认为群集中没有Leader，服务器会进入LOOKING状态，目的是为了查找或者选举Leader；
    * FOLLOWING：follower角色；
    * LEADING：leader角色；
    * OBSERVING：observer角色；

  * Zookeeper是通过自身的状态来区分自己所属的角色，来执行自己应该的任务。

  * ZAB状态：反映Zookeeper从选举到对外提供服务的过程中的四个步骤

    * ELECTION: 集群进入选举状态，此过程会选出一个节点作为leader角色；
    * DISCOVERY：连接上leader，响应leader心跳，并且检测leader的角色是否更改，通过此步骤之后选举出的leader才能执行真正职务；
    * SYNCHRONIZATION：整个集群都确认leader之后，将会把leader的数据同步到各个节点，保证整个集群的数据一致性；
    * BROADCAST：过渡到广播状态，集群开始对外提供服务。

  * **ZXID**

    Zxid是极为重要的概念，它是一个long型（64位）整数，分为两部分：纪元（epoch）部分和计数器（counter）部分，是一个**全局有序**的数字。

    epoch代表当前集群所属的哪个leader，leader的选举就类似一个朝代的更替，你前朝的剑不能斩本朝的官，用epoch代表当前命令的有效性，counter是一个递增的数字。

  * 选举发生的时机

    * Leader发生选举有两个时机，一个是服务启动的时候当整个集群都没有leader节点会进入选举状态，如果leader已经存在就会告诉该节点leader的信息，自己连接上leader，整个集群不用进入选举状态。

      还有一个就是在服务运行中，可能会出现各种情况，服务宕机、断电、网络延迟很高的时候leader都不能再对外提供服务了，所有当其他几点通过心跳检测到leader失联之后，集群也会进入选举状态。

  * 选举规则：zab协议是按照几个比较规则来进行投票的筛选，如果你的票比我更好，就修改自身的投票信息，改投你当leader。

    * 当其他节点的纪元比自身高投它，如果纪元相同比较自身的zxid的大小，选举zxid大的节点，这里的zxid代表节点所提交事务最大的id，zxid越大代表该节点的数据越完整。

      最后如果epoch和zxid都相等，则比较服务的serverId，这个Id是配置zookeeper集群所配置的，所以我们配置zookeeper集群的时候可以把服务性能更高的集群的serverId配置大些，让性能好的机器担任leader角色。

  * 选举：

    * ![image-20210318110342010](https://gitee.com/picgo-table/picgo-img/raw/master/image/image-20210318110342010.png)
    * 所有节点第一票先选举自己当leader，将投票信息广播出去；
    * 从队列中接受投票信息；
    * 按照规则判断是否需要更改投票信息，将更改后的投票信息再次广播出去；
    * 判断是否有超过一半的投票选举同一个节点，如果是选举结束根据投票结果设置自己的服务状态，选举结束，否则继续进入投票流程。

  * 广播：

    * 集群在经过leader选举之后还会有连接leader和同步两个步骤，这里就不具体分析这两个步骤的流程了，主要介绍集群对外提供服务如何保证各个节点数据的一致性。

    * 特征：**有序性**是zab协议必须要保证的一个很重要的属性，因为zookeeper是以类似目录结构的数据结构存储数据的，必须要求命名的有序性。

      * **可靠传递:** 如果消息m由一台服务器传递，那么它最终将由所有服务器传递。
      * **全局有序:** 如果一个消息a在消息b之前被一台服务器交付，那么所有服务器都交付了a和b，并且a先于b。
      * **因果有序:** 如果消息a在因果上先于消息b并且二者都被交付，那么a必须排在b之前。

    * 当收到客户端的写请求的时候会经历以下几个步骤：

      1. Leader收到客户端的写请求，生成一个事务（Proposal），其中包含了zxid；
      2. Leader开始广播该事务，需要注意的是所有节点的通讯都是由一个FIFO的队列维护的；
      3. Follower接受到事务之后，将事务写入本地磁盘，写入成功之后返回Leader一个ACK；
      4. Leader收到过半的ACK之后，开始提交本事务，并广播事务提交信息
      5. 从节点开始提交本事务。

      有以上流程可知，zookeeper通过二阶段提交来保证集群中数据的一致性，因为只需要收到过半的ACK就可以提交事务，所以zookeeper的数据并不是强一致性。

      zab协议的有序性保证是通过几个方面来体现的，第一是，服务之前用TCP协议进行通讯，保证在网络传输中的有序性；第二，节点之前都维护了一个FIFO的队列，保证全局有序性；第三，通过全局递增的zxid保证因果有序性。

  * 状态流转

    * 服务在启动或者和leader失联之后服务状态转为LOOKING；
    * 如果leader不存在选举leader，如果存在直接连接leader，此时zab协议状态为ELECTION；
    * 如果有超过半数的投票选择同一台server，则leader选举结束，被选举为leader的server服务状态为LEADING，其他server服务状态为FOLLOWING/OBSERVING；
    * 所有server连接上leader，此时zab协议状态为DISCOVERY；
    * leader同步数据给learner，使各个从节点数据和leader保持一致，此时zab协议状态为SYNCHRONIZATION；
    * 同步超过一半的server之后，集群对外提供服务，此时zab状态为BROADCAST。

    可以知道整个zookeeper服务的工作流程类似一个状态机的转换，而zab协议就是驱动服务状态流转的关键，理解了zab就理解了zookeeper工作的关键原理



### Spring Cloud

* 分布式：分布式系统是一组计算机，通过网络相互连接传递消息与通信后并协调它们的行为而形成的系统。**组件之间彼此进行交互以实现一个共同的目标**。
* CAP：**CAP理论定义的其实是在容忍网络分区的条件下，“强一致性”和“极致可用性”无法同时达到**。
  * C：数据一致性(consistency)：**所有**节点拥有数据的最新版本
  * A：可用性(availability)：数据具备高可用性
  * P：分区容错性(partition-tolerance)：**容忍网络出现分区**，分区之间网络不可达。

* eureka

  * 服务提供者

  * - **服务注册：**启动的时候会通过发送REST请求的方式将**自己注册到Eureka Server上**，同时带上了自身服务的一些元数据信息。
    - **服务续约：**在注册完服务之后，**服务提供者会维护一个心跳**用来持续告诉Eureka Server:  "我还活着 ” 、
    - **服务下线：**当服务实例进行正常的关闭操作时，它会**触发一个服务下线的REST请求**给Eureka Server, 告诉服务注册中心：下线了

  * 服务消费者

  * - **获取服务：**当我们**启动服务消费者**的时候，它会发送一个REST请求给服务注册中心，来获取上面注册的服务清单
    - **服务调用：**服务消费者在获取服务清单后，通过**服务名**可以获得具体提供服务的实例名和该实例的元数据信息。在进行服务调用的时候，**优先访问同处一个Zone中的服务提供方**。

  * Eureka Server(服务注册中心)：

  * - **失效剔除：**默认每隔一段时间（默认为60秒） 将当前清单中超时（默认为90秒）**没有续约的服务剔除出去**。
    - **自我保护：**。EurekaServer 在运行期间，会统计心跳失败的比例在15分钟之内是否低于85%(通常由于网络不稳定导致)。Eureka Server会将当前的**实例注册信息保护起来**， 让这些实例不会过期，尽可能**保护这些注册信息**。

* ribbon负载均衡

  * Ribbon是支持负载均衡，默认的负载均衡策略是轮询，我们也是可以根据自己实际的需求自定义负载均衡策略的。

  * 客户端负载均衡(Ribbon)

  * - 服务实例的**清单在客户端**，客户端进行负载均衡算法分配。
    - (从上面的知识我们已经知道了：客户端可以从Eureka Server中得到一份服务清单，在发送请求时通过负载均衡算法，**在多个服务器之间选择一个进行访问**)

  * 服务端负载均衡(Nginx)

  * - 服务实例的**清单在服务端**，服务器进行负载均衡算法分配

* Hystrix：断路器、线程隔离等进行服务保护
  * Fallback(失败快速返回)：当某个服务单元发生故障（类似用电器发生短路）之后，通过断路器的故障监控（类似熔断保险丝）， **向调用方返回一个错误响应， 而不是长时间的等待**。这样就不会使得线程因调用故障服务被长时间占用不释放，**避免**了故障在分布式系统中的**蔓延**。
  * 资源/依赖隔离(线程池隔离)：它会为**每一个依赖服务创建一个独立的线程池**，这样就算某个依赖服务出现延迟过高的情况，也只是对该依赖服务的调用产生影响， 而**不会拖慢其他的依赖服务**。

* Feign远程调用
  * Feign是一种声明式、模板化的HTTP客户端。在Spring Cloud中使用Feign, 我们可以做到使用HTTP请求远程服务时能与调用本地方法一样的编码体验，开发者完全感知不到这是远程方法，更感知不到这是个HTTP请求。

* Zuul	

  * SpringCloud Zuul通过与SpringCloud Eureka进行整合，将自身注册为Eureka服务治理下的应用，同时从Eureka中获得了所有其他微服务的实例信息。**外层调用都必须通过API网关**，使得**将维护服务实例的工作交给了服务治理框架自动完成**。

  * 在API网关服务上进行统一调用来**对微服务接口做前置过滤**，以实现对微服务接口的**拦截和校验**。

  * 可以实现：路由匹配(动态路由)、过滤器实现(动态过滤器)、默认会过滤掉Cookie与敏感的HTTP头信息(额外配置)

* config
  * Spring Cloud Config项目是一个解决分布式系统的配置管理方案。它包含了Client和Server两个部分，**server提供配置文件的存储、以接口的形式将配置文件的内容提供出去，client通过接口获取数据、并依据此数据初始化自己的应用**。
  * 简单来说，使用Spring Cloud Config就是将配置文件放到**统一的位置管理**(比如GitHub)，客户端通过接口去获取这些配置文件。
  * 在GitHub上修改了某个配置文件，应用加载的就是修改后的配置文件。


